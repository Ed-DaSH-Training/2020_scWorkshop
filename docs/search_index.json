[
["index.html", "ANALYSIS OF SINGLE CELL RNA-SEQ DATA 1 Introduction 1.1 COURSE OVERVIEW 1.2 TARGETED AUDIENCE &amp; ASSUMED BACKGROUND 1.3 COURSE FORMAT 1.4 Getting Started 1.5 SESSION CONTENT", " ANALYSIS OF SINGLE CELL RNA-SEQ DATA Orr Ashenberg Dana Silverbush Kirk Gosik 03/23/2020 - 03/27/2020 1 Introduction 1.1 COURSE OVERVIEW In recent years single cell RNA-seq (scRNA-seq) has become widely used for transcriptome analysis in many areas of biology. In contrast to bulk RNA-seq, scRNA-seq provides quantitative measurements of the expression of every gene in a single cell. However, to analyze scRNA-seq data, novel methods are required and some of the underlying assumptions for the methods developed for bulk RNA-seq experiments are no longer valid. In this course we will cover all steps of the scRNA-seq processing, starting from the raw reads coming off the sequencer. The course includes common analysis strategies, using state-of-the-art methods and we also discuss the central biological questions that can be addressed using scRNA-seq. 1.2 TARGETED AUDIENCE &amp; ASSUMED BACKGROUND This course is aimed at researchers and technical workers who are or will be analyzing scRNA-seq data. The material is suitable both for experimentalists who want to learn more about data-analysis as well as computational biologists who want to learn about scRNASeq methods. Examples demonstrated in this course can be applied to any experimental protocol or biological system. The requirements for this course are: 1. Working knowledge of unix (managing files, running programs) 2. Programming experience in R (writing a function, basic I/O operations, variable types, using packages). Bioconductor experience is a plus. 3. Familiarity with next-generation sequencing data and its analyses (using alignment and quantification tools for bulk sequencing data) 1.3 COURSE FORMAT The course will be delivered over the course of five days. Each day will include a lecture and laboratory component. The lecture will introduce the topics of discussion and the laboratory sessions will be focused on practical hands-on analysis of scRNA-seq data. These sessions will involve a combination of both mirroring exercises with the instructor to demonstrate a skill as well as applying these skills on your own to complete individual exercises. After and during each exercise, interpretation of results will be discussed as a group. Computing will be done using a combination of tools installed on the attendees laptop computer and web resources accessed via web browser. 1.4 Getting Started 1.5 SESSION CONTENT 1.5.1 Monday – Classes from 08:00 to 16:00 (lunch break-1 hr, 40 min of total coffee breaks) Shared Google doc - course notes, ideas/questions/challenges/interesting topics you would like to explore. 1.5.1.1 Lecture 1 – scRNA-Seq experimental design (Orr) Overview of course General introduction: cell atlas overviews Comparison of Bulk and single cell RNA-Seq Overview of available scRNA-seq technologies (10x) and experimental protocols scRNA-Seq experimental design and analysis workflow? 1.5.1.2 Lab 1 – Understanding sequencing raw data, downloading Docker if not done already (Kirk) 1.5.1.3 Lab based around data wrangling from public data repositories: get data from 10x website, single cell portal, from GEO (fastqs, counts) Shell and Unix commands to navigate directories, create folders, open files Raw file formats 1.5.1.4 Lecture 2 - Intro to Data processing: from bcl file to bam file, Transcriptome quantification: from bam file to counts (Dana) scRNA-Seq processing workflow starting with choice of sequencer (NextSeq, HiSeq, MiSeq) / barcode swapping and bcl files Overview of Popular tools and algorithms Common single-cell analyses and interpretation Sequencing data: alignment and quality control Looking at cool things in alignment like where reads are, mutations, splicing Read &amp; UMI counting (Kallisto alignment-free pseudocounts as well), how RSEM works (length dependence, sequencing depth, multimapping reads), CellRanger (dropest), bustools 10x barcode structure and links to Perturb-seq Gene length &amp; coverage Gene expression units (count data Smart-seq2 counts or 10x UMIs vs expression data) 1.5.1.5 Lab 2 – Processing raw scRNA-Seq data (Dana), Docker setup (Kirk) Data outputs from different scRNAseq technologies (10x, Smart-seq2) - process both? Demultiplexing sequencing data Read Quality Control (CellRanger, dropEst, fastqc) Run bowtie2 on 2 wells to demonstrate alignment Read alignment and visualization (kallisto, RSEM, Igviewer) Demultiplexing FastQC Align (STAR/TOPHAT/Kallisto) IGViewer - what do we want here? I use it for mutation detections, copying sequences, searching for alternative splicing. 1.5.1.6 Flash talks (1.5 hr, break into 2 groups of 13) placed into a dropbox 1 slide advertising or summarizing the poster. So you can introduce yourselves and we can get to know each other. No questions, 2 minutes. Two sessions, 15 people each. 1.5.2 Tuesday – Classes from 08:00 to 16:00 1.5.2.1 Lab 3 - Introduction to R (Kirk) Some R overview slides, https://r4ds.had.co.nz/ Installing packages Data-types Data manipulation, slicing Strings manipulations Introducing object oriented programming / S4 objects Visualization tools Bonus create FeaturePlot from Seurat in base ggplot Bonus: run RSEM on Dana’s bam files if you are bored 1.5.2.2 Lecture 3 - Expression QC, normalisation and gene-level batch correction (Orr) What CellRanger does for quality filtering PBMC data Normalisation methods https://www.nature.com/articles/nmeth.4292 Doublets, empty droplets, CellBender Barcode swapping Regression with technical covariates What about imputation? 1.5.2.3 Lab 4 – Data wrangling for scRNAseq data (Dana) Data structures and file formats for single-cell data Quality control of cells and genes (doublets, ambient, empty drops) Data exploration: violin plots… Introducing Seurat object Genes House keeping genes Mitochondrial genes Filter Normalize Find variable genes Scaling Regression Calculate a signature 1.5.2.4 Flash talks (1.5 hr, break into 2 groups of 13) placed into a dropbox 1 slide advertising or summarizing the poster. So you can introduce yourselves and we can get to know each other. No questions, 2 minutes. Two sessions, 15 people each. 1.5.3 Wednesday – Classes from 08:00 to 16:00 1.5.3.1 Lecture 4 (may start late Tuesday) - Identifying cell populations (Kirk) Feature selection Dimensionality reduction Clustering and assigning identity (Louvain, NMF, topic models, variational autoencoder) Differential expression tests 1.5.3.2 Lab 5 – Feature selection &amp; Clustering analysis (Kirk) Parameters and clustering Comparison of feature selection methods 1.5.3.3 Lecture 5 - Batch effects correction (Orr) Batch correction methods (regress out batch, scaling within batch, Seurat v3, MNN, Liger, Harmony, scvi, scgen) Evaluation methods for batch correction (ARI, average silhouette width, kBET…) 1.5.3.4 Lab 6 - Correcting batch effects (Orr) Comparison of batch correction methods, Seurat pancreas Use Seurat Wrappers? 1.5.4 Thursday – Classes from 08:00 to 16:00 Deciding on discussion topics for next day based on shared google doc. 1.5.4.1 Lecture 6 - Advanced topics (Kirk) Pseudotime inference Differential expression through pseudotime Deep learning or spatial data depending on questionnaire (20ish min, autoencoder as nonlinear dimension reduction, scvi, what questions to ask to evaluate whether a more advanced model helps, how to decide it’s safe to use a method, tradeoffs between method complexity and interpretability) 1.5.4.2 Lab 7 - Functional and Pseudotime analysis (Orr) Popular tools and packages for functional analysis (https://github.com/dynverse/dynmethods#list-of-included-methods) Review concepts from papers Comparison of pseudotime methods 1.5.4.3 Lecture 7 - Single-cell multi-omic technologies (Dana) Introduction to other omic data types Integrating scRNA-seq with other single-cell modalities (CITE, Perturb, ATAC, methylation…) 1.5.4.4 Lab 8 - Analysis of CITE-seq, scATAC-seq (Orr) https://github.com/Hoohm/CITE-seq-Count https://cite-seq.com/eccite-seq/ https://support.10xgenomics.com/single-cell-vdj/index/doc/technical-note-assay-scheme-and-configuration-of-chromium-single-cell-vdj-libraries https://satijalab.org/seurat/multimodal_vignette.html https://www.bioconductor.org/packages/devel/bioc/vignettes/cicero/inst/doc/website.html 1.5.5 Friday – Classes from 08:00 to 16:00 Small group discussion on selected topics through hangouts . #### Lab 10 - small dataset for analysis and office hours focused on select topics (Dana) For project on last day (plan for whole day), Dana will prepare datasets for 3 or more ish mut glioma tumors that they will download beforehand. The datasets may need to be subsampled to save time. Can do pseudotime, can run scvi, nmf. Groups of 3 students. "],
["experimental-design.html", "2 Experimental Design 2.1 Slides", " 2 Experimental Design 2.1 Slides "],
["understanding-sequencing-raw-data.html", "3 Understanding Sequencing Raw Data 3.1 Class Environment 3.2 Shell and Unix commands 3.3 File formats 3.4 Public data repositories 3.5 Docker Commands", " 3 Understanding Sequencing Raw Data 3.1 Class Environment 3.1.1 Getting into AWS Instance There is a nice breakdown from another Physalia course on instructions for different operating systems and accessing AWS. It is called Connection to the Amazon EC2 service. This will help with connecting to the AWS instance to run docker. ## Example ssh -i berlin.pem ubuntu@&lt;PUBLIC IP ADDRESS&gt; (e.g.34.219.254.245) ## Actual Command Example ssh -i berlin.pem ubuntu@34.213.180.241 3.2 Shell and Unix commands 3.2.1 Common Linux Commands 3.2.1.1 Lab 1a check the your present directory pwd check history history pipe history to grep to search for the cd command history | grep cd put history into a history.txt file history &gt; history.txt make a directory called data mkdir data change into data directory cd data move history.txt file into data directory mv ../history.txt ./ check manual page of wget command man wget redirect wget maunual page output into a file called wget.txt man wget &gt; wget.txt return the lines that contain output in the wget.txt file cat wget.txt | grep output grep -i output wget.txt Compress wget.txt file gzip wget.txt View Compressed file cat wget.txt.qz zcat wget.txt.qz zcat wget.txt.qz | less 3.2.1.2 Git Commands Git is a distributed version-control system for tracking changes in source code during software development. It is designed for coordinating work among programmers, but it can be used to track changes in any set of files. Its goals include speed, data integrity, and support for distributed, non-linear workflows. Go to your user directory and run the following command from git. This will create a directory of all the course material inside your user directory. After it is done cloning change directory into the 2020_scWorkshop directory where the course material is. The commands are below. ## clone repository git clone https://github.com/broadinstitute/2020_scWorkshop.git cd 2020_scWorkshop 3.3 File formats bcl fastq bam mtx, tsv hdf5 (.h5, .h5ad) 3.3.1 View FASTQ Files 3.3.1.1 Viewing entire file cat data/example_fastq.fastq 3.3.1.2 Viewing first 10 lines head data/example_fastq.fastq 3.3.1.3 Stream Viewing with less command less data/example_fastq.fastq 3.3.2 View BAM Files 3.3.2.1 Viewing first 10 lines samtools view data/ex1.bam | head 3.3.2.2 Stream Viewing with less command samtools view data/ex1.bam | less 3.4 Public data repositories 3.4.1 Cellranger/10x 3.4.1.1 Lab 1b 10x PBMC data are hosted in https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz get 10x PBMC data unzip data explore directory explore files wget https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz cd .. 3.4.2 GEO https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81905 3.4.2.1 Lab 1c Get GEO Data - ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL19057_series_matrix.txt.gz - ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL17021_series_matrix.txt.gz go into that directory get files and place them in the directory View files (try keeping in compressed format and view that way) wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE81nnn/GSE81905/matrix/GSE81905-GPL19057_series_matrix.txt.gz cd data; tar -xzf GSE81905-GPL19057_series_matrix.txt.gz cd .. 3.4.3 Single Cell Portal https://portals.broadinstitute.org/single_cell Study: Salk Institute - Single-cell Methylome Sequencing Identifies Distinct Neuronal Populations in Mouse Frontal Cortex 3.4.3.1 Lab 1d Get R2 fastq file from the Salk Institute study Look at files 3.4.3.2 Lab 1e Get Docker on your local computer for you to have Explore Single Cell Portal Explore GEO 3.5 Docker Commands Docker provides a consistent compute enviornment to ensure all software that you need is on the machine and able to be used. It will give you the version you need and help reduce software conflicts that may arise. make sure you are in the directory from the cloned repository directory run following command to start docker script # chmod 600 ./docker/run_docker_bash.sh ./docker/run_docker_bash.sh The full command inside the script is below. There is also an explaination of each part for your reference. ## if you are the super user on your computer docker run --rm -it -v $PWD:/home/rstudio kdgosik/2020scworkshop bash ## if you need to access permission to run the command sudo docker run --rm -it -v $PWD:/home/rstudio kdgosik/2020scworkshop bash Explaination of commands - docker: command to run docker - run: asking docker to run a container - --rm: flag to remove the container when you exit from it - nothing will be saved from your session to access again later - this flag can be removed to keep container - -it: flag to run the container interactively - this will keep all session output displaying on the terminal - to stop container go to terminal and press Crtl+c -v $PWD:/home/rstudio: map your home directory to a directory inside docker container called home - kdgosik/2020scworkshop: the image to run. It will be the image into a container if not already built on your computer - [image link](https://hub.docker.com/r/kdgosik/2020scworkshop) - bash: The entry point into the container. Start on the bash command line "],
["transcriptome-quantification.html", "4 Transcriptome Quantification 4.1 Google Slides", " 4 Transcriptome Quantification 4.1 Google Slides "],
["processing-scrnaseq-data.html", "5 Processing scRNAseq Data 5.1 Goal 5.2 Further reading 5.3 Download data 5.4 Align the reads 5.5 Visualization", " 5 Processing scRNAseq Data 5.1 Goal To give you experience with examining and aligning fastq files 5.2 Further reading This lab is based on a lab given in: http://hemberg-lab.github.io/scRNA.seq.course/processing-raw-scrna-seq-data.html For more exercises and ideas please visit their web-site! 5.3 Download data Please downlaod the 6 files from the dropbox folder: https://www.dropbox.com/sh/98573jes82w0fi7/AAB7Yhwe05MCZTnTZmppxZuta?dl=0 into the data folder of your copy of github: cd 2020_scWorkshop/data mkdir lab2data and copy the files into it ## FastQC Once you’ve obtained your single-cell RNA-seq data, the first thing you need to do with it is check the quality of the reads you have sequenced. For this task, today we will be using a tool called FastQC. FastQC is a quality control tool for sequencing data, which can be used for both bulk and single-cell RNA-seq data. FastQC takes sequencing data as input and returns a report on read quality. Copy and paste this link into your browser to visit the FastQC website: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ This website contains links to download and install FastQC and documentation on the reports produced. Fortunately we have already installed FastQC for you today, so instead we will take a look at the documentation. Scroll down the webpage to ‘Example Reports’ and click ‘Good Illumina Data’. This gives an example of what an ideal report should look like for high quality Illumina reads data. Now let’s make a FastQC report ourselves. Today we will be performing our analysis using a single cell from an mESC dataset produced by (Kolodziejczyk et al. 2015), which you downloaded froom the github link. The cells were sequenced using the SMART-seq2 library preparation protocol and the reads are paired end. First, let’s open the docker in a bash mode. open a terminal, cd to the docer folder (the folder you downloaded from github) and run this command: docker run --rm -ti -v $PWD:/home/rstudio -e DISABLE_AUTH=true kdgosik/2020scworkshop bash navigate to your data folder: cd home/rstudio/lab2data ls You should see the files that you downloaded from the dropbox link. Now let’s look at the files: less Teichmann_2i_2_2_1.fastq less Teichmann_2i_2_2_2.fastq We run fastqc from /usr/local/src/FastQC. You may need to give yourself permissions to run the file (hint: chmod) Task 1: run fastqc to view the quality of the reads chmod 755 /usr/local/src/FastQC/fastqc /usr/local/src/FastQC/fastqc -h This command will tell you what options are available to pass to FastQC. Let us direct our output to our personal directories (under the folder results). Feel free to ask for help if you get stuck! If you are successful, you should generate a .zip and a .html file for both the forwards and the reverse reads files. Once you have been successful, feel free to have a go at the next section. /usr/local/src/FastQC/fastqc -o &lt;output_folder&gt; Teichmann_2i_2_2_1.fastq Teichmann_2i_2_2_2.fastq Once the command has finished executing, you should have a total of four files - one zip file for each of the paired end reads, and one html file for each of the paired end reads. The report is in the html file. for those working in AWS, if you want to view the file you will need to download it to your computer. The scp command is: scp -r -i &lt;your pem file&gt; &lt;username&gt;@ec2-34-213-180-241.us-west-2.compute.amazonaws.com:~/&lt;file to copy&gt; &lt;destination in your computer&gt; Once the file is on you computer, click on it. Your FastQC report should open. Have a look through the file. Remember to look at both the forwards and the reverse end read reports! How good quality are the reads? Is there anything we should be concerned about? 5.3.1 Fastq file format FastQ is the most raw form of scRNASeq data you will encounter. All scRNASeq protocols are sequenced with paired-end sequencing. Barcode sequences may occur in one or both reads depending on the protocol employed. However, protocols using unique molecular identifiers (UMIs) will generally contain one read with the cell and UMI barcodes plus adapters but without any transcript sequence. Thus reads will be mapped as if they are single-end sequenced despite actually being paired end. FastQ files have the format: &gt;ReadID READ SEQUENCE + SEQUENCING QUALITY SCORES 5.4 Align the reads 5.4.1 STAR align Now we have established that our reads are of good quality, we would like to map them to a reference genome. This process is known as alignment. Some form of alignment is generally required if we want to quantify gene expression or find genes which are differentially expressed between samples. Many tools have been developed for read alignment, but today we will focus on STAR. For each read in our reads data, STAR tries to find the longest possible sequence which matches one or more sequences in the reference genome. Because STAR is able to recognize splicing events in this way, it is described as a ‘splice aware’ aligner. Usually STAR aligns reads to a reference genome, potentially allowing it to detect novel splicing events or chromosomal rearrangements. However, one issue with STAR is that it needs a lot of RAM, especially if your reference genome is large (eg. mouse and human). To speed up our analysis today, we will use STAR to align reads from to a reference transcriptome of 2000 transcripts. Note that this is NOT normal or recommended practice, we only do it here for reasons of time. We recommend that normally you should align to a reference genome. Two steps are required to perform STAR alignment. In the first step, the user provides STAR with reference genome sequences (FASTA) and annotations (GTF), which STAR uses to create a genome index. In the second step, STAR maps the user’s reads data to the genome index. Let’s create the index now. Remember, for reasons of time we are aligning to a transcriptome rather than a genome today, meaning we only need to provide STAR with the sequences of the transcripts we will be aligning reads to. You can obtain transcriptomes for many model organisms from Ensembl (https://www.ensembl.org/info/data/ftp/index.html). Task 2: Create a genome index First create the output folder for the index in your personal folder under results (recommended /home/rstudio/lab2data/STAR/indices). We run STAR from: /usr/local/src/STAR/bin/Linux_x86_64 using the command: /usr/local/src/STAR/bin/Linux_x86_64/STAR --runThreadN 4 --runMode genomeGenerate --genomeDir &lt;output STAR indices folder&gt; --genomeFastaFiles /home/rstudio/lab2data/2000_reference.transcripts.fa Now that we have created the index, we can perform the mapping step. Task 4: Try to work out what command you should use to map our fastq files to the index you created. Use the STAR manual to help you. Once you think you know the answer use ./STAR command to align the fastq files to a BAM file. You can either create a SAM file and convert it to BAM using samtools, or use STAR to directly output a BAM file (–outSAMtype BAM Unsorted) /usr/local/src/STAR/bin/Linux_x86_64/STAR --runThreadN 4 --genomeDir &lt;genome_reference&gt; --readFilesIn /home/rstudio/lab2data/Teichmann_2i_2_2_1.fastq /home/rstudio/lab2data/Teichmann_2i_2_2_2.fastq --outFileNamePrefix &lt;output_folder&gt; --outSAMtype BAM Unsorted The alignment may take awhile, if you wish to you can complete tasks 7-10 in the meanwhile. 5.4.2 Bam file format BAM file format stores mapped reads in a standard and efficient manner. The human-readable version is called a SAM file, while the BAM file is the highly compressed version. BAM/SAM files contain a header which typically includes information on the sample preparation, sequencing and mapping; and a tab-separated row for each individual alignment of each read. Alignment rows employ a standard format with the following columns: QNAME : read name (generally will include UMI barcode if applicable) FLAG : number tag indicating the “type” of alignment, link to explanation of all possible “types” RNAME : reference sequence name (i.e. chromosome read is mapped to). POS : leftmost mapping position MAPQ : Mapping quality CIGAR : string indicating the matching/mismatching parts of the read (may include soft-clipping). RNEXT : reference name of the mate/next read PNEXT : POS for mate/next read TLEN : Template length (length of reference region the read is mapped to) SEQ : read sequence QUAL : read quality BAM/SAM files can be converted to the other format using ‘samtools’: samtools view -S -b file.sam &gt; file.bam samtools view -h file.bam &gt; file.sam Some sequencing facilities will automatically map your reads to the a standard genome and deliver either BAM or CRAM formatted files. Generally they will not have included ERCC sequences in the genome thus no ERCC reads will be mapped in the BAM/CRAM file. To quantify ERCCs (or any other genetic alterations) or if you just want to use a different alignment algorithm than whatever is in the generic pipeline (often outdated), then you will need to convert the BAM/CRAM files back to FastQs: BAM files can be converted to FastQ using bedtools. To ensure a single copy for multi-mapping reads first sort by read name and remove secondary alignments using samtools. Picard also contains a method for converting BAM to FastQ files. Bonus: To make our aligned BAM file easy to navigate (needed for IGViewer) we will sort and index it using samtools. Sam tools can be run from everywhere (no need to go to a special directory!) using the command: samtools Let us start by sorting the BAM file: samtools sort Aligned.out.bam -o Aligned.out.sorted.bam Task 6: can you index the file? hint: try looking at samtools -h samtools index Aligned.out.sorted.bam Once you sorted and indexed the files you should have a BAM and a bai files. The BAM file is the aligned reads, and the bai is an index file. To view them in IGViewer (IGV) first copy them into your computer. Go ahead and copy the fa file as well, we will need a reference genome file. 5.5 Visualization To view the file we will use the IGV you installed on your personal computer. Open IGV: the default genomes are human HG19 and HG38. Through the class we will be using the PBMC dataset. You have the BAM file in your data folder. Go ahead and transfer it to your computer and upload it to IGV with hg38 as reference genome. Task 7: Browse to MS4A1, this is a blood cell marker. Can you see the exons and the introns? Where are most of the aligned reads? Task 8: Search in IGV or online - can you present splice junctions? (right click -&gt; “Show splice junction track”) Task 9: Try further tasks that interest you in IGV. For example, can you detect reads that are within one exon and reads that start in one exon and continue in the next? Can you copy the sequence of exon2 in MS4A1? Task 10: What would have happened if you chose the wrong reference genome, such as hg19? Bonus 2 (IGV sometimes has difficulties loading small fa files. So if this becomes difficult - don’t worry! It’s not your alignment): The default genomes are human HG19 and HG38. However you can also upload your reference genome of choice. As we created our own fasta file we can now upload it as a reference genome. Task 11: Load new genome: go to “Genomes”-&gt;”Load from file” and load the file 2000_reference.transcripts.fa Task 12: Now load your reads: go to “File”-&gt;”Load from file” and load your BAM file. Notice that IGV needs a BAM and a bai saved in the same location. IGV uses the bai to navigate through the BAM file. Task 13: Some of the reads have a nucleotide substitution in position 993 - what is the reference nucleotide? What is the substitution? "],
["introduction-rbioconductor.html", "6 Introduction R/Bioconductor 6.1 Start Environment 6.2 Installing packages 6.3 Installation instructions: 6.4 More information 6.5 Grammer of Graphics (ggplot2) 6.6 Reference", " 6 Introduction R/Bioconductor # mkdir data wget https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz cd .. 6.1 Start Environment 6.1.1 Local Command # chmod 600 ./docker/run_docker.sh ./docker/run_docker.sh full command ## maybe take away the --rm so they can save the container for later ## run from your home directory cd 2020scworkshop ## example for user17 docker run --rm -it -e DISABLE_AUTH=true \\ -v $PWD:/home/rstudio \\ -p 8787:8787 kdgosik/2020scworkshop Explaination of commands - docker: command to run docker - run: asking docker to run a container - --rm: flag to remove the container when you exit from it - nothing will be saved from your session to access again later - this flag can be removed to keep container - -it: flag to run the container interactively - - this will keep all session output displaying on the terminal - - to stop container go to terminal and press Crtl+c - -v $PWD:/home/rstudio: map your home directory to a directory inside docker container called home/rstudio - -p 8787:8787: map docker container port of 8787(rstudio port default) to your computer port 8787 - kdgosik/2020scworkshop: the image to run. It will be the image into a container if not already built on your computer - [image link](https://hub.docker.com/r/kdgosik/2020scworkshop) 6.1.2 AWS Command # chmod 600 ./docker/run_docker.sh ./docker/run_docker_aws.sh 9017 ## maybe take away the --rm so they can save the container for later ## run from your home directory cd 2020scworkshop ## example for user17 docker run --rm -it -e PASSWORD=train \\ -v $PWD:/home/rstudio \\ -p 9017:8787 kdgosik/2020scworkshop Explaination of commands - docker: command to run docker - run: asking docker to run a container - --rm: flag to remove the container when you exit from it - nothing will be saved from your session to access again later - this flag can be removed to keep container - -it: flag to run the container interactively - - this will keep all session output displaying on the terminal - - to stop container go to terminal and press Crtl+c - -v $PWD:/home/rstudio: map your home directory to a directory inside docker container called home/rstudio - -p 9017:8787: map docker container port of 8787(rstudio port default) to your computer port 9017 - kdgosik/2020scworkshop: the image to run. It will be the image into a container if not already built on your computer - [image link](https://hub.docker.com/r/kdgosik/2020scworkshop) localhost:9099 or on AWS :9017 ec2-.us-west-2.compute.amazonaws.com:$PORT_NUMBER ec2-54-202-32-102.us-west-2.compute.amazonaws.com:9017 R/Rstudio parts Data Types and classes Packages and where to get them S3 vs S4 Visualizations and ggplot Installing packages Data-types Data manipulation, slicing Strings manipulations Introducing object oriented programming / S4 objects Visualization tools Bonus create FeaturePlot from Seurat in base ggplot Bonus: run RSEM on Dana’s bam files if you are bored 6.2 Installing packages 6.2.1 CRAN The Comprehensive R Archive Network CRAN is the biggest archive of R packages. There are few requirements for uploading packages besides building and installing succesfully, hence documentation and support is often minimal and figuring how to use these packages can be a challenge it itself. CRAN is the default repository R will search to find packages to install: install.packages(&quot;devtools&quot;) # or multiple packages install.packages(c(&quot;ggplot2&quot;, &quot;stringr&quot;)) 6.2.2 Github Github isn’t specific to R, any code of any type in any state can be uploaded. There is no guarantee a package uploaded to github will even install, nevermind do what it claims to do. R packages can be downloaded and installed directly from github using the “devtools” package installed above. ## username/repository devtools::install_github(&quot;satijalab/seurat&quot;) # latest stable version of Seurat package Github is also a version control system which stores multiple versions of any package. By default the most recent “master” version of the package is installed. If you want an older version or the development branch this can be specified using the “ref” parameter: # different branch devtools::install_github(&quot;satijalab/seurat&quot;, ref=&quot;release3.0&quot;) # previous commit ## Merge branch &#39;develop&#39; into feat/MultiModal ## - Shiwei Zheng committed on Jul 2, 2018 devtools::install_github(&quot;tallulandrews/M3Drop&quot;, ref=&quot;551014f488770627ab154a62e59d49df5df98a3f&quot;) Note: make sure you re-install the M3Drop master branch for later in the course. 6.2.3 Bioconductor Bioconductor is a repository of R-packages specifically for biological analyses. It has the strictest requirements for submission, including installation on every platform and full documentation with a tutorial (called a vignette) explaining how the package should be used. Bioconductor also encourages utilization of standard data structures/classes and coding style/naming conventions, so that, in theory, packages and analyses can be combined into large pipelines or workflows. Bioconductor also requires creators to support their packages and has a regular 6-month release schedule. Make sure you are using the most recent release of bioconductor before trying to install packages for the course. ## &gt;= R 3.5.0 if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;Rsamtools&quot;, ask = FALSE) 6.2.4 Source The final way to install packages is directly from source. In this case you have to download a fully built source code file, usually packagename.tar.gz, or clone the github repository and rebuild the package yourself. Generally this will only be done if you want to edit a package yourself, or if for some reason the former methods have failed. You can also get previous packages that aren’t supported any more on the CRAN package archive ## Get an old package and install from source install.packages(&quot;GenABEL_1.8-0.tar.gz&quot;, type=&quot;source&quot;) 6.3 Installation instructions: All the packages necessary for this course are available here. A list of the packages will be on the README.md for the repository. A script is also available inside the docker/install.R file. 6.3.1 Classes/Types R is a high level language so the underlying data-type is generally not important. The exception if you are accessing R data directly using another language such as C, but that is beyond the scope of this course. Instead we will consider the basic data classes: numeric, integer, logical, and character, and the higher level data class called “factor”. You can check what class your data is using the “class()” function. 6.3.1.1 Integer x &lt;- 4 ## assign value of 4 to x class(x) ## check class of x ## [1] &quot;numeric&quot; is.integer(x) ## check if x is an integer ## [1] FALSE is.numeric(x) ## check if x is numeric ## [1] TRUE x &lt;- as.numeric(x) ## assign y to be an numeric is.numeric(x) ## check if the assignment worked ## [1] TRUE class(x) ## check if the assignment worked ## [1] &quot;numeric&quot; x ## check value of x ## [1] 4 6.3.1.2 Numeric ## assign value of 1.414 to y y &lt;- 1.414 ## check class of y class(y) ## [1] &quot;numeric&quot; ## check if y is numeric is.numeric(y) ## [1] TRUE ## check if y is an integer is.integer(y) ## [1] FALSE ## assign y to be an integer y &lt;- as.integer(y) ## check if the assignment worked is.integer(y) ## [1] TRUE ## check value of y y ## [1] 1 6.3.1.3 Logical/ Boolean The logical class stores boolean truth values, i.e. TRUE and FALSE. It is used for storing the results of logical operations and conditional statements will be coerced to this class. Most other data-types can be coerced to boolean without triggering (or “throwing”) error messages, which may cause unexpected behaviour. z &lt;- TRUE ## assign value of TRUE to z class(z) ## check class of z ## [1] &quot;logical&quot; is.logical(z) ## check if z is of logical type ## [1] TRUE 6.3.2 Data structures Homogeneous 1D: atomic vector 2D: matrix nD: array Heterogeneous 1D: list 2D: data.frame 6.3.2.1 Character Vectors ## assign a character vector with c() operator character_vector &lt;- c(&quot;A&quot;, &quot;C&quot;, &quot;T&quot;, &quot;G&quot;, &quot;C&quot;, &quot;T&quot;, &quot;G&quot;, &quot;C&quot;, &quot;G&quot;, &quot;A&quot;, &quot;T&quot;, &quot;G&quot;, &quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;A&quot;, &quot;C&quot;) ## check class class(character_vector) ## [1] &quot;character&quot; ## access the 3rd element with [] operator ## *note*: R is index starts at 1 (other programming languages start at 0) character_vector[3] ## [1] &quot;T&quot; ## access 3rd through 6th elemenet character_vector[3:6] ## [1] &quot;T&quot; &quot;G&quot; &quot;C&quot; &quot;T&quot; ## access the elements 1,4,7,10 with c() character_vector[c(1, 4, 7, 10)] ## [1] &quot;A&quot; &quot;G&quot; &quot;G&quot; &quot;A&quot; ## access all the A&#39;s character_vector[grep(&quot;A&quot;, character_vector)] ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; 6.3.2.2 Numeric Vector The “numeric” class is the default class for storing any numeric data - integers, decimal numbers, numbers in scientific notation, etc… ## assign a character vector with c() operator numeric_vector &lt;- c(1, 5, 21, 17, 98, 35, 11, 13) ## check class class(numeric_vector) ## [1] &quot;numeric&quot; ## access the 5th element with [] operator numeric_vector[5] ## [1] 98 ## access 2nd through 4th elemenet numeric_vector[2:4] ## [1] 5 21 17 ## backticks ` ` allow you to give names with non-typical characters `numeric?_vecotr` &lt;- c(&quot;A&quot;, 1, 5, 21, 17, 98, 35, 11, 13) ## check vector `numeric?_vecotr` ## [1] &quot;A&quot; &quot;1&quot; &quot;5&quot; &quot;21&quot; &quot;17&quot; &quot;98&quot; &quot;35&quot; &quot;11&quot; &quot;13&quot; ## check class (Notice the quotation marks on the numbers!) class(`numeric?_vecotr`) ## [1] &quot;character&quot; 6.3.2.3 Factor Vector String/Character data is very memory inefficient to store, each letter generally requires the same amount of memory as any integer. Thus when storing a vector of strings with repeated elements it is more efficient assign each element to an integer and store the vector as integers and an additional string-to-integer association table. Thus, by default R will read in text columns of a data table as factors. factor_vector &lt;- factor(numeric_vector) factor_vector ## [1] 1 5 21 17 98 35 11 13 ## Levels: 1 5 11 13 17 21 35 98 6.3.2.4 Named Vector names(numeric_vector) &lt;- paste0(&quot;Patient&quot;, 1 : length(numeric_vector)) numeric_vector ## Patient1 Patient2 Patient3 Patient4 Patient5 Patient6 Patient7 Patient8 ## 1 5 21 17 98 35 11 13 6.3.2.5 List ## change the c() operator to list() operator new_list &lt;- list(&quot;A&quot;, 1, 5, 21, 17, 98, 35, 11, 13) new_list ## [[1]] ## [1] &quot;A&quot; ## ## [[2]] ## [1] 1 ## ## [[3]] ## [1] 5 ## ## [[4]] ## [1] 21 ## ## [[5]] ## [1] 17 ## ## [[6]] ## [1] 98 ## ## [[7]] ## [1] 35 ## ## [[8]] ## [1] 11 ## ## [[9]] ## [1] 13 ## get 2nd element of list new_list[[2]] ## [1] 1 names(new_list) &lt;- paste0(&quot;Patient&quot;, 1 : length(new_list)) new_list ## $Patient1 ## [1] &quot;A&quot; ## ## $Patient2 ## [1] 1 ## ## $Patient3 ## [1] 5 ## ## $Patient4 ## [1] 21 ## ## $Patient5 ## [1] 17 ## ## $Patient6 ## [1] 98 ## ## $Patient7 ## [1] 35 ## ## $Patient8 ## [1] 11 ## ## $Patient9 ## [1] 13 ## get 2nd element of list new_list[[2]] ## [1] 1 2D 6.3.2.6 matrix Create Matrix ## create numeric matrix numeric_matrix &lt;- matrix(sample(1:10, 100, replace = TRUE), nrow = 10, ncol = 10) class(numeric_matrix) ## check class ## [1] &quot;matrix&quot; Check Structure str(numeric_matrix) ## int [1:10, 1:10] 8 6 9 10 4 9 3 3 9 7 ... Get 3rd Row ## get 3rd row numeric_matrix[3, ] ## [1] 9 5 4 10 5 7 2 10 1 2 Get 4th Column ## get 4th colum numeric_matrix[, 4] ## [1] 3 3 10 8 8 2 10 3 1 1 6.3.2.7 data.frame Get data.frame ## built in R data.frame iris head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Check Class class(iris) ## [1] &quot;data.frame&quot; Check Structure str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Get 3rd Row ## get 3rd row iris[3,] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 3 4.7 3.2 1.3 0.2 setosa Get 4th Column ## get 4th colum iris[,4] ## [1] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 ## [19] 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.2 0.2 ## [37] 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 ## [55] 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 ## [73] 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 ## [91] 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 ## [109] 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 ## [127] 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 ## [145] 2.5 2.3 1.9 2.0 2.3 1.8 Get 3rd Row ## get 3rd row numeric_matrix[3, ] ## [1] 9 5 4 10 5 7 2 10 1 2 Get Species Variable ## get variable iris$Species ## [1] setosa setosa setosa setosa setosa setosa ## [7] setosa setosa setosa setosa setosa setosa ## [13] setosa setosa setosa setosa setosa setosa ## [19] setosa setosa setosa setosa setosa setosa ## [25] setosa setosa setosa setosa setosa setosa ## [31] setosa setosa setosa setosa setosa setosa ## [37] setosa setosa setosa setosa setosa setosa ## [43] setosa setosa setosa setosa setosa setosa ## [49] setosa setosa versicolor versicolor versicolor versicolor ## [55] versicolor versicolor versicolor versicolor versicolor versicolor ## [61] versicolor versicolor versicolor versicolor versicolor versicolor ## [67] versicolor versicolor versicolor versicolor versicolor versicolor ## [73] versicolor versicolor versicolor versicolor versicolor versicolor ## [79] versicolor versicolor versicolor versicolor versicolor versicolor ## [85] versicolor versicolor versicolor versicolor versicolor versicolor ## [91] versicolor versicolor versicolor versicolor versicolor versicolor ## [97] versicolor versicolor versicolor versicolor virginica virginica ## [103] virginica virginica virginica virginica virginica virginica ## [109] virginica virginica virginica virginica virginica virginica ## [115] virginica virginica virginica virginica virginica virginica ## [121] virginica virginica virginica virginica virginica virginica ## [127] virginica virginica virginica virginica virginica virginica ## [133] virginica virginica virginica virginica virginica virginica ## [139] virginica virginica virginica virginica virginica virginica ## [145] virginica virginica virginica virginica virginica virginica ## Levels: setosa versicolor virginica 6.3.3 Detour to S3/S4 S3 most of R uses Bioconductor requires R packages to be written as S4 objects OO field guide Closer to a typical programming language Classes/Methods and Generics Lots of Generics implemented for Bioinformatics! Different way to access values. Need to use the @ symbol instead of $ (@ is equivalent to $, and slot() to [[.) ## example object@ 6.3.3.1 Sparse Matrix Triplet format for storing a matrix row, column, value i, p, x Different from base R. Uses the S4 methods that Bioconductor uses. sparse_matrix &lt;- pbmc_small@data[1:10, ] class(sparse_matrix) ith row - 1 sparse_matrix@i pth column - 1 sparse_matrix@p value sparse_matrix@x Get First Value sparse_matrix[2,1] dense matrix dense_matrix &lt;- as.matrix(sparse_matrix) class(dense_matrix) str(dense_matrix) Get First Value dense_matrix[2,1] 6.3.3.2 Functions create_function &lt;- function(x, y) { } 6.3.3.3 Reading Files ## read csv files read.csv(&quot;PATH/TO/FILENAME.csv&quot;) ## read tsv files read.delim(&quot;PATH/TO/FILENAME.tsv&quot;, sep = &#39;\\t&#39;) 6.4 More information You can get more information about any R commands relevant to these datatypes using by typing ?function in an interactive session. 6.4.1 Checking for help for any function! start with a ? (this indicates you need the help menu) then the function name to get help on library(ggplot2) ?ggplot ## ggplot is a function, how do we use it? 6.5 Grammer of Graphics (ggplot2) 6.5.1 What is ggplot2? ggplot2 is an R package designed by Hadley Wickham which facilitates data plotting. In this lab, we will touch briefly on some of the features of the package. If you would like to learn more about how to use ggplot2, we would recommend reading “ggplot2 Elegant graphics for data analysis”, by Hadley Wickham or checking out his original paper on the package Data: Always start with the data, identify the dimensions you want to visualize. Aesthetics: Confirm the axes based on the data dimensions, positions of various data points in the plot. Also check if any form of encoding is needed including size, shape, color and so on which are useful for plotting multiple data dimensions. Scale: Do we need to scale the potential values, use a specific scale to represent multiple values or a range? Geometric objects: These are popularly known as ‘geoms’. This would cover the way we would depict the data points on the visualization. Should it be points, bars, lines and so on? Statistics: Do we need to show some statistical measures in the visualization like measures of central tendency, spread, confidence intervals? Facets: Do we need to create subplots based on specific data dimensions? Coordinate system: What kind of a coordinate system should the visualization be based on — should it be cartesian or polar? 6.5.2 Principles of ggplot2 Your data must be a dataframe if you want to plot it using ggplot2. Use the aes mapping function to specify how variables in the dataframe map to features on your plot Use geoms to specify how your data should be represented on your graph eg. as a scatterplot, a barplot, a boxplot etc. Data: Always start with the data, identify the dimensions you want to visualize. library(Seurat) library(ggplot2) gbm &lt;- pbmc_small@assays$RNA@data gbm &lt;- as.data.frame(as.matrix(t(gbm))) new_plot &lt;- ggplot(gbm) Aesthetics: Confirm the axes based on the data dimensions, positions of various data points in the plot. Also check if any form of encoding is needed including size, shape, color and so on which are useful for plotting multiple data dimensions. 1D Plots new_plot_1dx &lt;- ggplot(gbm, aes(x = MS4A1)) new_plot_1dx Scale: Do we need to scale the potential values, use a specific scale to represent multiple values or a range? Geometric objects: These are popularly known as ‘geoms’. This would cover the way we would depict the data points on the visualization. Should it be points, bars, lines and so on? ## ggplot(gbm, aes(x = MS4A1)) + geom_histogram() ## or ## new_plot_1dx &lt;- new_plot_1dx + geom_histogram() ## reassign new_plot_1dx + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 6.5.2.1 Lab A Use different geom_ to make a different plots - try _bar() - try _density() new_plot_1dx + geom_density() Statistics: Do we need to show some statistical measures in the visualization like measures of central tendency, spread, confidence intervals? ggplot(gbm, aes(x = MS4A1)) + geom_histogram() + stat_bin(bins = 10) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 2D Plots new_plot_2d &lt;- ggplot(gbm, aes(x = MS4A1, y = CD79B)) ## scatter plot new_plot_2d + geom_point() 6.5.2.2 Lab B Use different geom_ to make a different plots - try _bar_abline() - try _bin2d() new_plot_2d Adding Statisitics in 2D plots Regression line (lm - linear model using OLS regression) ggplot(gbm, aes(MS4A1, CD79B)) + geom_point() + stat_smooth(method = &quot;lm&quot;) Adding Text Labels ## notice plus `+` at the end of each line, adding a new layer! ggplot(gbm, aes(MS4A1, CD79B)) + ## Data layer geom_point() + ## Geometry layer stat_smooth(method = &quot;lm&quot;) + ## geom_text(aes(label = rownames(gbm))) 6.5.2.3 Lab C Play arund with ggplot2. See what geoms to add and layers to include. ggplot(gbm, aes(x = MS4A1, y = CD79B)) 6.6 Reference R for Data Science Advanced R Bioconductor Workflows Bioconductor Presentation Original ggplot2 paper ggplot2 reference ggplot2 cheatsheet blog post Hemberg Lab "],
["quality-control.html", "7 Quality Control 7.1 Slides", " 7 Quality Control 7.1 Slides "],
["data-wrangling-scrnaseq.html", "8 Data Wrangling scRNAseq 8.1 Goal 8.2 Introduction 8.3 Filtering low-quality cells 8.4 Beginning with Seurat: http://satijalab.org/seurat/ 8.5 Preprocessing step 1 : Filter out low-quality cells 8.6 Examine contents of Seurat object 8.7 Detection of variable genes across the single cells 8.8 Gene set expression across cells", " 8 Data Wrangling scRNAseq 8.1 Goal To give you experience with the analysis of single cell RNA sequencing (scRNA-seq) including performing quality control and identifying cell type subsets. To introduce you to scRNA-seq analysis using the Seurat package. 8.2 Introduction Data produced in a single cell RNA-seq experiment has several interesting characteristics that make it distinct from data produced in a bulk population RNA-seq experiment. Two characteristics that are important to keep in mind when working with scRNA-Seq are drop-out (the excessive amount of zeros due to limiting mRNA) and the potential for quality control (QC) metrics to be confounded with biology. This combined with the ability to measure heterogeniety from cells in samples has shifted the field away from the typical analysis in population-based RNA-Seq. Here we demonstrate some approaches to quality control, followed by identifying and analyzing cell subsets. For this tutorial, we will be analyzing the a dataset of Non-Small Cell Lung Cancer Cells (NSCLC) freely available from 10X Genomics (https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex), using the Seurat R package (http://satijalab.org/seurat/), a popular and powerful set of tools to conduct scRNA-seq analysis in R. In this dataset, there are 7802 single cells that were sequenced on the Illumina NovaSeq 6000. Please note this tutorial borrows heavily from Seurat’s tutorials, so feel free to go through them in more detail. 8.2.1 Load necessary packages When loading libraries, we are asking R to load code for us written by someone else. It is a convenient way to leverage and reproduce methodology developed by others. library(Seurat) library(dplyr) library(Matrix) library(gdata) 8.2.2 Read in NSCLC counts matrix. The data for Non-Small Cell Lung Cancer Cells (NSCLC) is freely available from 10X Genomics (https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex). We start by reading in the counts matrix generated by the Cell Ranger count program. Task: Change the directory name to read your data dirname &lt;- &quot;/data/&quot; counts_matrix_filename = paste0(dirname,&quot;/filtered_gene_bc_matrices/GRCh38/&quot;) counts &lt;- Read10X(data.dir = counts_matrix_filename) # Seurat function to read in 10x count data # To minimize memory use on the docker - choose only the first 1000 cells counts &lt;- counts[,1:1000] 8.2.3 Let’s examine the sparse counts matrix counts[1:10, 1:3] Here we see the upper left corner of the sparse matrix. The columns are indexed by 10x cell barcodes (each 16 nt long), and the rows are the gene names. We mentioned these matrices are sparse, here we see only zeroes (indicated by the “.” symbol); this is the most common value in these sparse matrices. Next, let us look at the dimensions of this matrix. 8.2.4 How big is the matrix? dim(counts) # report number of genes (rows) and number of cells (columns) Here we see the counts matrix has 33694 genes and 7802 cells. 8.2.5 How much memory does a sparse matrix take up relative to a dense matrix? object.size(counts) # size in bytes object.size(as.matrix(counts)) # size in bytes We see here that the sparse matrix takes 225 Mb in memory while storing the matrix in a dense format (where all count values including zeros are stored) takes almost 10 times as much memory! This memory saving is very important, especially as data sets are now being created that are beyond a million cells. These matrices can become unmanageable without special computing resources. In the sparse representation, we assume that the majority of count values in a matrix are zero. We only store the non-zero values. This is implemented in the Matrix package using a dgTMatrix object. 8.3 Filtering low-quality cells You can learn a lot about your scRNA-seq data’s quality with simple plotting. Let’s do some plotting to look at the number of reads per cell, reads per genes, expressed genes per cell (often called complexity), and rarity of genes (cells expressing genes). 8.3.1 Look at the summary counts for genes and cells counts_per_cell &lt;- Matrix::colSums(counts) counts_per_gene &lt;- Matrix::rowSums(counts) genes_per_cell &lt;- Matrix::colSums(counts&gt;0) # count gene only if it has non-zero reads mapped. Task: In a similar way, can you calculate cells per genes? replace the ‘?’ in the command below cells_per_gene &lt;- Matrix::?(counts&gt;?) # only count cells where the gene is expressed colSums and rowSums are functions that work on each row or column in a matrix and return the column sums or row sums as a vector. If this is true counts_per_cell should have 1 entry per cell. Let’s make sure the length of the returned vector matches the matrix dimension for column. How would you do that? ( Hint:length() ). Notes: 1. Matrix::colSums is a way to force functions from the Matrix library to be used. There are many libraries that implement colSums, we are forcing the one from the Matrix library to be used here to make sure it handles the dgTmatrix (sparse matrix) correctly. This is good practice. hist(log10(counts_per_cell+1),main=&#39;counts per cell&#39;,col=&#39;wheat&#39;) hist(log10(genes_per_cell+1), main=&#39;genes per cell&#39;, col=&#39;wheat&#39;) plot(counts_per_cell, genes_per_cell, log=&#39;xy&#39;, col=&#39;wheat&#39;) title(&#39;counts vs genes per cell&#39;) Here we see examples of plotting a new plot, the histogram. R makes this really easy with the hist function. We are also transforming the values to log10 before plotting, this is done with the log10 method. When logging count data, the + 1 is used to avoid log10(0) which is not defined. Can you a histogram of counts per gene in log10 scale? hist(?(?+1), main=&#39;counts per gene&#39;, col=&#39;wheat&#39;) 8.3.2 Plot cells ranked by their number of detected genes. Here we rank each cell by its library complexity, ie the number of genes detected per cell. This is a very useful plot as it shows the distribution of library complexity in the sequencing run. One can use this plot to investigate observations (potential cells) that are actually failed libraries (lower end outliers) or observations that are cell doublets (higher end outliers). plot(sort(genes_per_cell), xlab=&#39;cell&#39;, log=&#39;y&#39;, main=&#39;genes per cell (ordered)&#39;) 8.4 Beginning with Seurat: http://satijalab.org/seurat/ 8.4.1 Creating a seurat object To analyze our single cell data we will use a seurat object. Can you create an Seurat object with the 10x data and save it in an object called ‘seurat’? hint: CreateSeuratObject(). Can you include only genes that are are expressed in 3 or more cells and cells with complexity of 350 genes or more? How many genes are you left with? How many cells? seurat&lt;-CreateSeuratObject(counts = counts, ? = 3, ? = 350, project = &quot;10X_NSCLC&quot;) Almost all our analysis will be on the single object, of class Seurat. This object contains various “slots” (designated by seurat@slotname) that will store not only the raw count data, but also the results from various computations below. This has the advantage that we do not need to keep track of inidividual variables of interest - they can all be collapsed into a single object as long as these slots are pre-defined. The Assay class stores single cell data. For typical scRNA-seq experiments, a Seurat object will have a single Assay (“RNA”). This assay will also store multiple ‘transformations’ of the data, including raw counts ((???) slot), normalized data ((???) slot), and scaled data for dimensional reduction ((???) slot). seurat@assays$RNA is a slot that stores the original gene count matrix. We can view the first 10 rows (genes) and the first 10 columns (cells). seurat@assays$RNA[1:10,1:10] 8.5 Preprocessing step 1 : Filter out low-quality cells The Seurat object initialization step above only considered cells that expressed at least 350 genes. Additionally, we would like to exclude cells that are damaged. A common metric to judge this (although by no means the only one) is the relative expression of mitochondrially derived genes. When the cells apoptose due to stress, their mitochondria becomes leaky and there is widespread RNA degradation. Thus a relative enrichment of mitochondrially derived genes can be a tell-tale sign of cell stress. Here, we compute the proportion of transcripts that are of mitochondrial origin for every cell (percent.mito), and visualize its distribution as a violin plot. We also use the GenePlot function to observe how percent.mito correlates with other metrics. # The number of genes and UMIs (nGene and nUMI) are automatically calculated for every object by Seurat. For non-UMI # data, nUMI represents the sum of the non-normalized values within a cell We calculate the percentage of mitochondrial # genes here and store it in percent.mito using AddMetaData. We use object@raw.data since this represents # non-transformed and non-log-normalized counts The % of UMI mapping to MT-genes is a common scRNA-seq QC metric. mito.genes &lt;- grep(pattern = &quot;^MT-&quot;, x = rownames(x = seurat@assays$RNA@data), value = TRUE) percent.mito &lt;- Matrix::colSums(seurat@assays$RNA@data[mito.genes, ])/Matrix::colSums(seurat@assays$RNA@data) # AddMetaData adds columns to object@meta.data, and is a great place to stash QC stats. This also allows us to plot the # metadata values using the Seurat&#39;s VlnPlot(). head(seurat@meta.data) # Before adding Task: Can you add the percentage if mitochondrial genes to the seurat object meta data? If you dont remember the name of the parameter you can type ?AddMetaData in the console. An alternative way to add meta data is by using: seurat[[“percent.mito”]] &lt;- PercentageFeatureSet(seurat, pattern = “^MT-”) seurat &lt;- AddMetaData(object = seurat, ? = percent.mito, col.name = &quot;percent.mito&quot;) head(seurat@meta.data) # After adding VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;, &quot;nCount_RNA&quot;, &quot;percent.mito&quot;)) Here we calculated the percent mitochondrial reads and added it to the Seurat object in the slot named meta.data. This allowed us to plot using the violin plot function provided by Seurat. A third metric we use is the number of house keeping genes expressed in a cell. These genes reflect commomn processes active in a cell and hence are a good global quality measure. They are also abundant and are usually steadliy expressed in cells, thus less sensitive to the high dropout. # Load the the list of house keeping genes hkgenes &lt;- read.table(&quot;/home/rstudio/data/resources/tirosh_house_keeping.txt&quot;, skip = 2) hkgenes &lt;- as.vector(hkgenes$V1) # remove hkgenes that were not found hkgenes.found &lt;- which(toupper(rownames(seurat@assays$RNA@data)) %in% hkgenes) Task: 1. Sum the number of detected house keeping genes for each cell 2. Add this information as meta data to seurat 3. plot all metrics: “nGene”, “nUMI”, “percent.mito”,“n.exp.hkgenes” using VlnPlot n.expressed.hkgenes &lt;- ?(seurat@assays$RNA@data[hkgenes.found, ] &gt; 0) seurat &lt;- AddMetaData(object = ?, ? = ?, col.name = &quot;n.exp.hkgenes&quot;) VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;, &quot;nCount_RNA&quot;, &quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), ncol = 4) Is there a correlation between the measurements? For example, number of UMIs with number of genes? Can you plot the nGene vs nUMI? What is the correlation? Do you see a strange subpopulation? What do you think happened with these cells? FeatureScatter(object = seurat, feature1 = ?, feature2 = ?) 8.6 Examine contents of Seurat object str(seurat) These are the slots in the Seurat object. Some of the slots are automatically updated by Seurat as you move through analysis. Take a moment to look through the information, knowing the slots allow you to leverage work Seurat has already done for you. VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;), group.by = c(&#39;orig.ident&#39;)) Here we plot the number of genes per cell by what Seurat calls orig.ident. Identity is a concept that is used in the Seurat object to refer to the cell identity. In this case, the cell identity is 10X_NSCLC, but after we cluster the cells, the cell identity will be whatever cluster the cell belongs to. We will see how identity updates as we go throught the analysis. Next, let’s filter the cells based on the quality control metrics. Filter based on: 1. nFeature_RNA 2. percent.mito 3. n.exp.hkgenes Task: Change the thresholds to what you think they should be according to the violin plots VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;,&quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), ncol = 3) seurat &lt;- subset(seurat, subset = nFeature_RNA &gt; 350 &amp; nFeature_RNA &lt; 4000 &amp; percent.mito &lt; 0.15 &amp; n.exp.hkgenes &gt; 55) How many cells are you left with? seurat 8.6.1 Preprocessing step 2 : Expression normalization After removing unwanted genes cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the gene expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. There have been many methods to normalize the data, but this is the simplest and the most intuitive. The division by total expression is done to change all expression counts to a relative measure, since experience has suggested that technical factors (e.g. capture rate, efficiency of reverse transcription) are largely responsible for the variation in the number of molecules per cell, although genuine biological factors (e.g. cell cycle stage, cell size) also play a smaller, but non-negligible role. The log-transformation is a commonly used transformation that has many desirable properties, such as variance stabilization (can you think of others?). seurat &lt;- NormalizeData(object = seurat, normalization.method = &quot;LogNormalize&quot;, scale.factor = 1e4) Well there you have it! A filtered and normalized gene-expression data set. A great accomplishment for your first dive into scRNA-Seq analysis. Well done! 8.7 Detection of variable genes across the single cells Seurat calculates highly variable genes and focuses on these for downstream analysis. FindVariableFeatures calculates the average expression and dispersion for each gene, places these genes into bins, and then calculates a z-score for dispersion within each bin. This helps control for the relationship between variability and average expression. seurat &lt;- FindVariableFeatures(seurat, selection.method = &quot;vst&quot;, nfeatures = 2000) # Identify the 10 most highly variable genes top10 &lt;- head(VariableFeatures(seurat), 10) # plot variable features with and without labels plot1 &lt;- VariableFeaturePlot(seurat) plot2 &lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE, xnudge = 0, ynudge = 0) plot1 + plot2 8.8 Gene set expression across cells Sometimes we want to ask what is the expression of a set of a genes across cells. This set of genes may make up a gene expression program we are interested in. Another benefit at looking at gene sets is it reduces the effects of drop outs. Below, we look at genes involved in: T cells, the cell cycle and the stress signature upon cell dissociation. We calculate these genes average expression levels on the single cell level, while controlling for technical effects. # Read in a list of cell cycle markers, from Tirosh et al, 2015. # We can segregate this list into markers of G2/M phase and markers of S phase. cc.genes &lt;- readLines(&quot;/home/rstudio/data/resources/regev_lab_cell_cycle_genes.txt&quot;) s.genes &lt;- cc.genes[1:43] g2m.genes &lt;- cc.genes[44:97] seurat &lt;- CellCycleScoring(seurat, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE) Task: Use markers for dissociation to calculate dissociation score # Genes upregulated during dissociation of tissue into single cells. genes.dissoc &lt;- c(&quot;ATF3&quot;, &quot;BTG2&quot;, &quot;CEBPB&quot;, &quot;CEBPD&quot;, &quot;CXCL3&quot;, &quot;CXCL2&quot;, &quot;CXCL1&quot;, &quot;DNAJA1&quot;, &quot;DNAJB1&quot;, &quot;DUSP1&quot;, &quot;EGR1&quot;, &quot;FOS&quot;, &quot;FOSB&quot;, &quot;HSP90AA1&quot;, &quot;HSP90AB1&quot;, &quot;HSPA1A&quot;, &quot;HSPA1B&quot;, &quot;HSPA1A&quot;, &quot;HSPA1B&quot;, &quot;HSPA8&quot;, &quot;HSPB1&quot;, &quot;HSPE1&quot;, &quot;HSPH1&quot;, &quot;ID3&quot;, &quot;IER2&quot;, &quot;JUN&quot;, &quot;JUNB&quot;, &quot;JUND&quot;, &quot;MT1X&quot;, &quot;NFKBIA&quot;, &quot;NR4A1&quot;, &quot;PPP1R15A&quot;, &quot;SOCS3&quot;, &quot;ZFP36&quot;) #### seurat &lt;- AddModuleScore(?, genes.list = list(?), ctrl.size = 20, enrich.name = &quot;genes_dissoc&quot;) seurat &lt;- AddModuleScore(seurat, features = list(genes.dissoc), ctrl.size = 20, enrich.name = &quot;genes_dissoc&quot;) Task: Plot the correlation between number of genes and S score. How do we know the name of these scores in the seurat meta data? FeatureScatter(seurat, feature1 = ?, &quot;nFeature_RNA&quot;) Congratulations! You can identify and visualize cell subsets and the marker genes that describe these cell subsets. This is a very powerful analysis pattern often seen in publications. Well done! library(Seurat) library(dplyr) library(Matrix) library(gdata) # read data dirname &lt;- &quot;/home/rstudio/data/&quot; counts_matrix_filename = paste0(dirname,&quot;/filtered_gene_bc_matrices/GRCh38/&quot;) counts &lt;- Read10X(data.dir = counts_matrix_filename) # Seurat function to read in 10x count data # To minimize memory use on the docker - choose only the first 1000 cells counts &lt;- counts[,1:1000] # Let&#39;s examine the sparse counts matrix counts[1:10, 1:3] # How big is the matrix? dim(counts) # report number of genes (rows) and number of cells (columns) # How much memory does a sparse matrix take up relative to a dense matrix? object.size(counts) # size in bytes object.size(as.matrix(counts)) # size in bytes # Look at the summary counts for genes and cells counts_per_cell &lt;- Matrix::colSums(counts) counts_per_gene &lt;- Matrix::rowSums(counts) genes_per_cell &lt;- Matrix::colSums(counts&gt;0) # count gene only if it has non-zero reads mapped. cells_per_gene &lt;- Matrix::rowSums(counts&gt;0) # only count cells where the gene is expressed # plot counts and genes hist(log10(counts_per_cell+1),main=&#39;counts per cell&#39;,col=&#39;wheat&#39;) hist(log10(genes_per_cell+1), main=&#39;genes per cell&#39;, col=&#39;wheat&#39;) plot(counts_per_cell, genes_per_cell, log=&#39;xy&#39;, col=&#39;wheat&#39;) title(&#39;counts vs genes per cell&#39;) # plot a histogram of counts per gene in log10 scale hist(log10(counts_per_gene+1), main=&#39;counts per gene&#39;, col=&#39;wheat&#39;) # Plot cells ranked by their number of detected genes. plot(sort(genes_per_cell), xlab=&#39;cell&#39;, log=&#39;y&#39;, main=&#39;genes per cell (ordered)&#39;) ## Beginning with Seurat: http://satijalab.org/seurat/ # create object seurat&lt;-CreateSeuratObject(counts = counts, min.cells = 3, min.features = 350, project = &quot;10X_NSCLC&quot;) # vcalculate percent pf mitochondria genes mito.genes &lt;- grep(pattern = &quot;^MT-&quot;, x = rownames(x = seurat@assays$RNA@data), value = TRUE) percent.mito &lt;- Matrix::colSums(seurat@assays$RNA@data[mito.genes, ])/Matrix::colSums(seurat@assays$RNA@data) #### seurat &lt;- AddMetaData(object = seurat, ? = percent.mito, col.name = &quot;percent.mito&quot;) seurat &lt;- AddMetaData(object = seurat, metadata = percent.mito, col.name = &quot;percent.mito&quot;) head(seurat@meta.data) # After adding VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;, &quot;nCount_RNA&quot;, &quot;percent.mito&quot;)) # Load the the list of house keeping genes hkgenes &lt;- read.table(&quot;/home/rstudio/data/resources/tirosh_house_keeping.txt&quot;, skip = 2) hkgenes &lt;- as.vector(hkgenes$V1) # remove hkgenes that were not found hkgenes.found &lt;- which(toupper(rownames(seurat@assays$RNA@data)) %in% hkgenes) # Add_number_of_house_keeping_genes n.expressed.hkgenes &lt;- Matrix::colSums(seurat@assays$RNA@data[hkgenes.found, ] &gt; 0) seurat &lt;- AddMetaData(object = seurat, metadata = n.expressed.hkgenes, col.name = &quot;n.exp.hkgenes&quot;) VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;, &quot;nCount_RNA&quot;, &quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), ncol = 4) FeatureScatter(object = seurat, feature1 = &quot;nFeature_RNA&quot;, feature2 = &quot;nCount_RNA&quot;) # plot seurat meta data VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;), group.by = c(&#39;orig.ident&#39;)) VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;,&quot;percent.mito&quot;,&quot;n.exp.hkgenes&quot;), ncol = 3) # filter data seurat &lt;- subset(seurat, subset = nFeature_RNA &gt; 350 &amp; nFeature_RNA &lt; 4000 &amp; percent.mito &lt; 0.15 &amp; n.exp.hkgenes &gt; 55) #normalize seurat &lt;- NormalizeData(object = seurat, normalization.method = &quot;LogNormalize&quot;, scale.factor = 1e4) #find_var_genes seurat &lt;- FindVariableFeatures(seurat, selection.method = &quot;vst&quot;, nfeatures = 2000) # Identify the 10 most highly variable genes top10 &lt;- head(VariableFeatures(seurat), 10) # plot variable features with and without labels plot1 &lt;- VariableFeaturePlot(seurat) plot2 &lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE, xnudge = 0, ynudge = 0) plot1 + plot2 #cell_cycle_genes # Read in a list of cell cycle markers, from Tirosh et al, 2015. # We can segregate this list into markers of G2/M phase and markers of S phase. cc.genes &lt;- readLines(&quot;/home/rstudio/data/resources/regev_lab_cell_cycle_genes.txt&quot;) s.genes &lt;- cc.genes[1:43] g2m.genes &lt;- cc.genes[44:97] seurat &lt;- CellCycleScoring(seurat, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE) #dissociation_signature # Genes upregulated during dissociation of tissue into single cells. genes.dissoc &lt;- c(&quot;ATF3&quot;, &quot;BTG2&quot;, &quot;CEBPB&quot;, &quot;CEBPD&quot;, &quot;CXCL3&quot;, &quot;CXCL2&quot;, &quot;CXCL1&quot;, &quot;DNAJA1&quot;, &quot;DNAJB1&quot;, &quot;DUSP1&quot;, &quot;EGR1&quot;, &quot;FOS&quot;, &quot;FOSB&quot;, &quot;HSP90AA1&quot;, &quot;HSP90AB1&quot;, &quot;HSPA1A&quot;, &quot;HSPA1B&quot;, &quot;HSPA1A&quot;, &quot;HSPA1B&quot;, &quot;HSPA8&quot;, &quot;HSPB1&quot;, &quot;HSPE1&quot;, &quot;HSPH1&quot;, &quot;ID3&quot;, &quot;IER2&quot;, &quot;JUN&quot;, &quot;JUNB&quot;, &quot;JUND&quot;, &quot;MT1X&quot;, &quot;NFKBIA&quot;, &quot;NR4A1&quot;, &quot;PPP1R15A&quot;, &quot;SOCS3&quot;, &quot;ZFP36&quot;) seurat &lt;- AddModuleScore(seurat, features = list(genes.dissoc), ctrl.size = 20, enrich.name = &quot;genes_dissoc&quot;) # correlation: cell cycle scoores and number of genes, eval = FALSE} FeatureScatter(seurat, feature1 = &quot;S.Score&quot;, &quot;nFeature_RNA&quot;) "],
["identifying-cell-populations.html", "9 Identifying Cell Populations 9.1 Google Slides", " 9 Identifying Cell Populations 9.1 Google Slides NEEDS UPDATED "],
["feature-selection-and-cluster-analysis.html", "10 Feature Selection and Cluster Analysis 10.1 Abstract 10.2 Seurat Tutorial Redo 10.3 Feature Selection 10.4 Other Options For Analysis 10.5 Load settings and packages 10.6 Read in pancreas expression matrices 10.7 Preparing the individual Seurat objects for each pancreas dataset without batch correction", " 10 Feature Selection and Cluster Analysis NEEDS UPDATED!! 10.1 Abstract Many methods have been used to determine differential gene expression from single-cell RNA (scRNA)-seq data. We evaluated 36 approaches using experimental and synthetic data and found considerable differences in the number and characteristics of the genes that are called differentially expressed. Prefiltering of lowly expressed genes has important effects, particularly for some of the methods developed for bulk RNA-seq data analysis. However, we found that bulk RNA-seq analysis methods do not generally perform worse than those developed specifically for scRNA-seq. We also present conquer, a repository of consistently processed, analysis-ready public scRNA-seq data sets that is aimed at simplifying method evaluation and reanalysis of published results. Each data set provides abundance estimates for both genes and transcripts, as well as quality control and exploratory analysis reports. (???) Cells are the basic building blocks of organisms and each cell is unique. Single-cell RNA sequencing has emerged as an indispensable tool to dissect the cellular heterogeneity and decompose tissues into cell types and/or cell states, which offers enormous potential for de novo discovery. Single-cell transcriptomic atlases provide unprecedented resolution to reveal complex cellular events and deepen our understanding of biological systems. In this review, we summarize and compare single-cell RNA sequencing technologies, that were developed since 2009, to facilitate a well-informed choice of method. The applications of these methods in different biological contexts are also discussed. We anticipate an ever-increasing role of single-cell RNA sequencing in biology with further improvement in providing spatial information and coupling to other cellular modalities. In the future, such biological findings will greatly benefit medical research. (???) 10.2 Seurat Tutorial Redo For this tutorial, we will be analyzing the a dataset of Peripheral Blood Mononuclear Cells (PBMC) freely available from 10X Genomics. There are 2,700 single cells that were sequenced on the Illumina NextSeq 500. The raw data can be found here. OR MAYBE USE THE vdj data? wget https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz cd .. Task: Check the dirname to directory where you saved your data knitr::opts_knit$set(progress=FALSE, verbose=FALSE) library(Seurat) library(dplyr) library(ggplot2) library(CountClust) dirname &lt;- &quot;data/&quot; ## dirname &lt;- &quot;/Users/kgosik/Documents/data/cellranger/&quot; counts_matrix_filename = paste0(dirname, &quot;filtered_gene_bc_matrices/hg19/&quot;) counts &lt;- Read10X(data.dir = counts_matrix_filename) # Seurat function to read in 10x count data ### seurat&lt;-CreateSeuratObject(raw.data = counts, ? = 3, ? = 350, project = &quot;10X_NSCLC&quot;) seurat &lt;- CreateSeuratObject(counts = counts, min.cells = 3, min.features = 350, project = &quot;10X_PBMC&quot;) 10.2.1 Preprocessing Steps This was all covered in the last Lab! # The number of genes and UMIs (nFeature_RNA nCount_RNA) are automatically calculated # for every object by Seurat. For non-UMI data, nCount_RNA represents the sum of # the non-normalized values within a cell We calculate the percentage of # mitochondrial genes here and store it in percent.mito using AddMetaData. # We use object@raw.data since this represents non-transformed and # non-log-normalized counts The % of UMI mapping to MT-genes is a common # scRNA-seq QC metric. seurat[[&quot;percent.mt&quot;]] &lt;- PercentageFeatureSet(object = seurat, pattern = &quot;^MT-&quot;) ##VlnPlot(object = seurat, features = c(&quot;nFeature_RNA&quot;, &quot;nCount_RNA&quot;, &quot;percent.mt&quot;), ncol = 3) # FeatureScatter is typically used to visualize gene-gene relationships, but can # be used for anything calculated by the object, i.e. columns in # object@meta.data, PC scores etc. Since there is a rare subset of cells # with an outlier level of high mitochondrial percentage and also low UMI # content, we filter these as well par(mfrow = c(1, 2)) FeatureScatter(object = seurat, feature1 = &quot;nCount_RNA&quot;, feature2 = &quot;percent.mt&quot;) FeatureScatter(object = seurat, feature1 = &quot;nCount_RNA&quot;, feature2 = &quot;nFeature_RNA&quot;) # We filter out cells that have unique gene counts over 2,500 or less than # 200 Note that low.thresholds and high.thresholds are used to define a # &#39;gate&#39;. -Inf and Inf should be used if you don&#39;t want a lower or upper # threshold. # seurat &lt;- SubsetData(object = seurat, # subset.names = c(&quot;nFeature_RNA&quot;, &quot;percent.mt&quot;), # low.thresholds = c(200, -Inf), # high.thresholds = c(2500, 0.1)) seurat &lt;- subset(seurat, nFeature_RNA &lt; 2500) seurat &lt;- subset(seurat, nFeature_RNA &gt; 200) seuart &lt;- subset(seurat, percent.mt &lt; 10) seurat &lt;- NormalizeData(object = seurat, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) # Read in a list of cell cycle markers, from Tirosh et al, 2015. # We can segregate this list into markers of G2/M phase and markers of S phase. s.genes &lt;- Seurat::cc.genes$s.genes s.genes &lt;- s.genes[s.genes %in% rownames(seurat)] # genes in dataset g2m.genes &lt;- Seurat::cc.genes$g2m.genes g2m.genes &lt;- g2m.genes[g2m.genes %in% rownames(seurat)] # genes in dataset seurat &lt;- CellCycleScoring(object = seurat, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE) seurat &lt;- FindVariableFeatures(object = seurat, mean.function = ExpMean, dispersion.function = LogVMR) 10.2.2 Start of Identifying Cell Types 10.2.2.1 Scaling This part is where you mean center the data, substract the mean. You also divide by the standard deviation to make everything to a ‘standard normal’, where the mean is zero and the standard deviation is 1. seurat &lt;- ScaleData(object = seurat, vars.to.regress = c(&quot;batch&quot;, &quot;percent.mt&quot;)) Task: Try Regressing Other Variables ## randomly making a batch id data.frame batch_ids &lt;- data.frame(barcode = rownames(seurat@meta.data), batch_id = sample(0:2, NROW(seurat@meta.data), replace = TRUE), stringsAsFactors = FALSE) row.names(batch_ids) &lt;- row.names(seurat@meta.data) seurat &lt;- AddMetaData(object = seurat, metadata = batch_ids, col.name = NULL) seurat &lt;- ScaleData(object = seurat, vars.to.regress = &#39;batch_id&#39;) 10.2.2.2 Perform linear dimensional reduction (PCA) This will run pca on the seurat &lt;- RunPCA(object = seurat, # features = seurat@assays$RNA@var.features, ndims.print = 1:5, nfeatures.print = 5) 10.2.2.3 Visualizing PCA in Different Ways DimPlot(seurat, reduction = &quot;pca&quot;) 10.2.2.4 Perform linear dimensional reduction (ICA) Task: Try running Independent Component Analysis. If you need help with the inputs try using the ?RunICA menu. seurat &lt;- RunICA() 10.2.2.5 Visualizing ICA in Different Ways DimPlot() # ProjectDim scores each gene in the dataset (including genes not included # in the PCA) based on their correlation with the calculated components. # Though we don&#39;t use this further here, it can be used to identify markers # that are strongly correlated with cellular heterogeneity, but may not have # passed through variable gene selection. The results of the projected PCA # can be explored by setting use.full=T in the functions above seurat &lt;- ProjectDim(object = seurat, reduction = &quot;pca&quot;) 10.2.2.6 Genes by PCs DimHeatmap(object = seurat, dims = 1:6, cells = 50, reduction = &quot;pca&quot;, balanced = TRUE) Check other PCs to plot Task: Check other PCs DimHeatmap() seurat &lt;- JackStraw(object = seurat, reduction = &quot;pca&quot;) seurat &lt;- ScoreJackStraw(seurat, dims = 1:20) JackStrawPlot(seurat, dims = 1:15) ElbowPlot(object = seurat, ndims = 10, reduction = &quot;pca&quot;) # save.SNN = T saves the SNN so that the clustering algorithm can be rerun # using the same graph but with a different resolution value (see docs for # full details) set.seed(2020) seurat &lt;- FindNeighbors(object = seurat, dims = 1:10) seurat &lt;- FindClusters(object = seurat, reduction = &quot;pca&quot;, dims = 1:10, resolution = 0.5, random.seed = 2020) 10.2.3 Run non-linear dimensional reduction (UMAP/tSNE) Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets. The goal of these algorithms is to learn the underlying manifold of the data in order to place similar cells together in low-dimensional space. Cells within the graph-based clusters determined above should co-localize on these dimension reduction plots. As input to the UMAP and tSNE, we suggest using the same PCs as input to the clustering analysis. set.seed(2020) seurat &lt;- RunTSNE(seurat, reduction.use = &quot;pca&quot;, dims.use = 1:10, perplexity=10) # note that you can set do.label=T to help label individual clusters DimPlot(object = seurat, reduction = &quot;tsne&quot;) Task: Try using UMAP for the non-linear dimension reduction technique (hint: ?RunUMAP) set.seed(2020) seurat &lt;- RunUMAP() # note that you can set label=TRUE to help label individual clusters DimPlot() 10.2.3.1 Finding differentially expressed features (cluster biomarkers) Seurat can help you find markers that define clusters via differential expression. By default, it identifes positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells. The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significiant and the most highly differentially expressed features will likely still rise to the top. # find all markers of cluster 1 using default parameters cluster1.markers &lt;- FindMarkers(object = seurat, ident.1 = 1, min.pct = 0.25) head(cluster1.markers) Task: Try tuning different parameters. How does that affect results? # find all markers distinguishing cluster 5 from clusters 0 and 1 cluster5.markers &lt;- FindMarkers(object = seurat, ident.1 = 5, ident.2 = c(0, 1), min.pct = ?? test.use = ??, only.pos = ??) head(cluster5.markers) cluster3.markers &lt;- FindMarkers(object = seurat, ident.1 = 3, thresh.use = 0.25, test.use = &quot;roc&quot;, only.pos = TRUE) head(cluster3.markers) VlnPlot(object = seurat, features = c(&quot;MS4A1&quot;, &quot;CD79A&quot;)) # you can plot raw UMI counts as well VlnPlot(object = seurat, features = c(&quot;NKG7&quot;, &quot;PF4&quot;), log = TRUE) # find markers for every cluster compared to all remaining cells, report # only the positive ones pbmc.markers &lt;- FindAllMarkers(object = seurat, only.pos = TRUE, min.pct = 0.25, thresh.use = 0.25) pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(2, avg_logFC) FeaturePlot(object = seurat, features = c(&quot;MS4A1&quot;, &quot;GNLY&quot;, &quot;CD3E&quot;, &quot;CD14&quot;, &quot;FCER1A&quot;, &quot;FCGR3A&quot;, &quot;LYZ&quot;, &quot;PPBP&quot;, &quot;CD8A&quot;), cols = c(&quot;grey&quot;, &quot;blue&quot;), reduction = &quot;tsne&quot;) top10 &lt;- pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(10, avg_logFC) # setting slim.col.label to TRUE will print just the cluster IDS instead of # every cell name DoHeatmap(object = seurat, features = top10$gene, label = TRUE) new.cluster.ids &lt;- c(&quot;Memory CD4 T&quot;, &quot;Naive CD4 T&quot;, &quot;CD14+ Mono&quot;, &quot;B&quot;, &quot;CD8 T&quot;, &quot;FCGR3A+ Mono&quot;, &quot;NK&quot;, &quot;DC&quot;, &quot;Mk&quot;) names(x = new.cluster.ids) &lt;- levels(x = seurat) seurat &lt;- RenameIdents(object = seurat, new.cluster.ids) DimPlot(object = seurat, reduction = &#39;tsne&#39;, label = TRUE, pt.size = 0.5) + NoLegend() 10.2.3.2 Further subdivisions within cell types If you perturb some of our parameter choices above (for example, setting resolution=0.8 or changing the number of PCs), you might see the CD4 T cells subdivide into two groups. You can explore this subdivision to find markers separating the two T cell subsets. However, before reclustering (which will overwrite object@ident), we can stash our renamed identities to be easily recovered later. # First lets stash our identities for later seurat[[&quot;ClusterNames_0.6&quot;]] &lt;- Idents(object = seurat) # Note that if you set save.snn=T above, you don&#39;t need to recalculate the # SNN, and can simply put: pbmc &lt;- FindClusters(pbmc,resolution = 0.8) seurat &lt;- FindClusters(object = seurat, reduction = &quot;pca&quot;, dims = 1:10, resolution = 0.8) set.seed(2020) ## Warning in BuildSNN(object = object, genes.use = genes.use, reduction.type ## = reduction.type, : Build parameters exactly match those of already ## computed and stored SNN. To force recalculation, set force.recalc to TRUE. # Demonstration of how to plot two tSNE plots side by side, and how to color # points based on different criteria plot1 &lt;- DimPlot(object = seurat, reduction= &quot;tsne&quot;, label = TRUE) + NoLegend() plot2 &lt;- DimPlot(object = seurat, reduction = &quot;tsne&quot;, group.by = &quot;ClusterNames_0.6&quot;, label = TRUE) + NoLegend() CombinePlots(list(plot1, plot2)) # Find discriminating markers tcell.markers &lt;- FindMarkers(object = seurat, ident.1 = 0, ident.2 = 1) # Most of the markers tend to be expressed in C1 (i.e. S100A4). However, we # can see that CCR7 is upregulated in C0, strongly indicating that we can # differentiate memory from naive CD4 cells. cols demarcates the color # palette from low to high expression FeaturePlot(object = seurat, features = c(&quot;S100A4&quot;, &quot;CCR7&quot;), cols = c(&quot;green&quot;, &quot;blue&quot;)) 10.3 Feature Selection 10.3.1 Differential Expression Analysis 10.3.1.1 Differential Expression Tests One of the most commonly performed tasks for RNA-seq data is differential gene expression (DE) analysis. Although well-established tools exist for such analysis in bulk RNA-seq data, methods for scRNA-seq data are just emerging. Given the special characteristics of scRNA-seq data, including generally low library sizes, high noise levels and a large fraction of so-called ‘dropout’ events, it is unclear whether DE methods that have been developed for bulk RNA-seq are suitable also for scRNA-seq. Check the help page out for the FindMarkers function by using ?FindMarkers ## Differential expression using t-test FindMarkers(object = seurat, ident.1 = 0, ident.2 = 1, test.use = &quot;t&quot;) Task: Try to use different test for diffential expression analysis (hint: ?FindMarkers) ## Use the help function and run other tests. Do they find similar markers? FindMarkers(object = seurat, ident.1 = 0, ident.2 = 1, test.use = ??) 10.3.2 Check Clusters How do we test the cell types identified? How do we know how reliable they are? Use Classifier to predict cell cluster. See how it predicts using hold out data. reference # Assign the test object a three level attribute groups &lt;- sample(c(&quot;train&quot;, &quot;test&quot;), size = NROW(seurat@meta.data), replace = TRUE, prob = c(0.8, 0.2)) names(groups) &lt;- colnames(seurat) seurat &lt;- AddMetaData(object = seurat, metadata = groups, col.name = &quot;group&quot;) # Find Anchors seurat.list &lt;- SplitObject(seurat, split.by = &quot;group&quot;) seurat.anchors &lt;- FindIntegrationAnchors(object.list = seurat.list, dims = 1:30) seurat.integrated &lt;- IntegrateData(anchorset = seurat.anchors, dims = 1:30) seurat.query &lt;- seurat.list[[&quot;train&quot;]] seurat.anchors &lt;- FindTransferAnchors(reference = seurat.integrated, query = seurat.query, dims = 1:30) predictions &lt;- TransferData(anchorset = seurat.anchors, refdata = seurat.integrated$ClusterNames_0.6, dims = 1:30) seurat.query &lt;- AddMetaData(seurat.query, metadata = predictions) table(seurat.query@meta.data$ClusterNames_0.6, seurat.query@meta.data$predicted.id) 10.3.3 View Entire Object Structure Notice all the slots and elements added to the object. str(seurat) 10.3.3.1 Probabilistic (LDA) Another type of clustering we can do is a fuzzy or probablistic clustering. This is where cells are not assigned to specifically only one cluster. They get assigned a score for how much the cells belong to each of the clusters (sometimes called topics). This can be helpful for when your dataset continuous processes and/or cellular states as opposed to distinct cell types. data(&quot;MouseDeng2014.FitGoM&quot;) names(MouseDeng2014.FitGoM) omega &lt;- MouseDeng2014.FitGoM$clust_6$omega annotation &lt;- data.frame( sample_id = paste0(&quot;X&quot;, c(1:NROW(omega))), tissue_label = factor(rownames(omega), levels = rev(c(&quot;zy&quot;, &quot;early2cell&quot;, &quot;mid2cell&quot;, &quot;late2cell&quot;, &quot;4cell&quot;, &quot;8cell&quot;, &quot;16cell&quot;, &quot;earlyblast&quot;, &quot;midblast&quot;, &quot;lateblast&quot;))) ) rownames(omega) &lt;- annotation$sample_id; StructureGGplot(omega = omega, annotation = annotation, palette = RColorBrewer::brewer.pal(8, &quot;Accent&quot;), yaxis_label = &quot;Amplification batch&quot;, order_sample = TRUE, axis_tick = list(axis_ticks_length = .1, axis_ticks_lwd_y = .1, axis_ticks_lwd_x = .1, axis_label_size = 7, axis_label_face = &quot;bold&quot;)) set.seed(2020) ## Preprocessing Steps pbmc_small &lt;- NormalizeData(object = pbmc_small, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) pbmc_small &lt;- RunPCA(object = pbmc_small) pbmc_small &lt;- FindClusters(object = pbmc_small, reduction = &quot;pca&quot;, dims.use = 1:10, resolution = 1, print.output = 0) pbmc_counts &lt;- as.matrix(pbmc_small@assays$RNA@data) pbmc_meta &lt;- pbmc_small@meta.data gene_names &lt;- rownames(pbmc_counts) pbmc_FitGoM &lt;- FitGoM(t(pbmc_counts), K=4) omega &lt;- data.frame(pbmc_FitGoM$fit$omega) annotation &lt;- data.frame(sample_id = rownames(omega), tissue_label = paste0(&quot;cluster&quot;, pbmc_small@active.ident)) colnames(omega) &lt;- paste0(&quot;topic&quot;, 1:4) rownames(omega) &lt;- annotation$sample_id; StructureGGplot(omega = omega, annotation = annotation, palette = RColorBrewer::brewer.pal(4, &quot;Dark2&quot;), yaxis_label = &quot;Cells&quot;, order_sample = TRUE, axis_tick = list(axis_ticks_length = .1, axis_ticks_lwd_y = .1, axis_ticks_lwd_x = .1, axis_label_size = 7, axis_label_face = &quot;bold&quot;)) # ## Add Topic Scores to Meta Data Part of the Seurat Object pbmc_small &lt;- AddMetaData(pbmc_small, omega) pbmc_small@meta.data %&gt;% group_by(RNA_snn_res.1) %&gt;% summarise(topic1 = mean(topic1), topic2 = mean(topic2), topic3 = mean(topic3), topic4 = mean(topic4)) ## ggplot object, you can add layers p1 &lt;- DimPlot(pbmc_small, reduction = &quot;tsne&quot;) + labs(title = &quot;Resolution 1&quot;) ## return ggplot object p1 p2 &lt;- FeaturePlot(object = pbmc_small, features = c(&quot;topic1&quot;, &quot;topic2&quot;, &quot;topic3&quot;, &quot;topic4&quot;), cols = c(&quot;grey&quot;, &quot;blue&quot;), reduction = &quot;tsne&quot;) ## return ggplot object p2 CombinePlots(list(p1, p2)) 10.3.3.2 Extract Top Feature theta_mat &lt;- pbmc_FitGoM$fit$theta top_features &lt;- ExtractTopFeatures(theta_mat, top_features=100, method=&quot;poisson&quot;, options=&quot;min&quot;) gene_list &lt;- do.call(rbind, lapply(1:dim(top_features$indices)[1], function(x) gene_names[top_features$indices[x,]])) We tabulate the top 5 genes for these 4 topics out_table &lt;- do.call(rbind, lapply(1:4, function(i) toString(gene_list[i,1:5]))) rownames(out_table) &lt;- paste(&quot;Topic&quot;, c(1:4)) out_table 10.3.4 Practice Visualizing/Embedding 10.3.4.1 tSNE Change the parameter settings for tSNE RunTSNE() 10.3.4.2 UMAP Change the parameter settings for UMAP RunUMAP() 10.4 Other Options For Analysis More Seurat Vignettes Single Cell Analysis Workshop Hemberg Lab Course SingleCellExperiment Scanpy Pegasus In this lab, we will look at different single cell RNA-seq datasets collected from pancreatic islets. We will look at how different batch correction methods affect our data analysis. Note: you can increase the system memory available to Docker by going to Docker -&gt; Preferences -&gt; Advanced and shifting the Memory slider. 10.5 Load settings and packages 10.6 Read in pancreas expression matrices # Read in all four input expression matrices celseq.data &lt;- read.table(paste0(mydir, &quot;pancreas_multi_celseq_expression_matrix.txt.gz&quot;)) celseq2.data &lt;- read.table(paste0(mydir, &quot;pancreas_multi_celseq2_expression_matrix.txt.gz&quot;)) fluidigmc1.data &lt;- read.table(paste0(mydir, &quot;pancreas_multi_fluidigmc1_expression_matrix.txt.gz&quot;)) smartseq2.data &lt;- read.table(paste0(mydir, &quot;pancreas_multi_smartseq2_expression_matrix.txt.gz&quot;)) # Convert to sparse matrices for efficiency celseq.data &lt;- as(as.matrix(celseq.data), &quot;dgCMatrix&quot;) celseq2.data &lt;- as(as.matrix(celseq2.data), &quot;dgCMatrix&quot;) fluidigmc1.data &lt;- as(as.matrix(fluidigmc1.data), &quot;dgCMatrix&quot;) smartseq2.data &lt;- as(as.matrix(smartseq2.data), &quot;dgCMatrix&quot;) 10.7 Preparing the individual Seurat objects for each pancreas dataset without batch correction # What is the size of each single cell RNA-seq dataset? # Briefly describe the technology used to collect each dataset. # Which datasets do you expect to be different and which do you expect to be similar? dim(celseq.data) dim(celseq2.data) dim(fluidigmc1.data) dim(smartseq2.data) # Create and setup Seurat objects for each dataset with the following 6 steps. # 1. CreateSeuratObject # 2. subset # 3. NormalizeData # 4. FindVariableGenes # 5. ScaleData # 6. Update @meta.data slot in Seurat object with tech column (celseq, celseq2, fluidigmc1, smartseq2) # Look at the distributions of number of genes per cell before and after FilterCells. # CEL-Seq (https://www.cell.com/cell-reports/fulltext/S2211-1247(12)00228-8) # In subset, use low.thresholds = 1750 celseq &lt;- CreateSeuratObject(counts = celseq.data) VlnPlot(celseq, &quot;nFeature_RNA&quot;) celseq &lt;- subset(celseq, subset = nFeature_RNA &gt; 1750) VlnPlot(celseq, &quot;nFeature_RNA&quot;) celseq &lt;- NormalizeData(celseq, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) celseq &lt;- FindVariableFeatures(celseq, selection.method = &quot;vst&quot;, nfeatures = 2000) celseq &lt;- ScaleData(celseq) celseq[[&quot;tech&quot;]] &lt;- &quot;celseq&quot; # CEL-Seq2 https://www.cell.com/molecular-cell/fulltext/S1097-2765(09)00641-8 # In subset, use low.thresholds = 2500. celseq2 &lt;- CreateSeuratObject(counts = celseq2.data) VlnPlot(celseq2, &quot;nFeature_RNA&quot;) celseq2 &lt;- subset(celseq2, subset = nFeature_RNA &gt; 2500) VlnPlot(celseq2, &quot;nFeature_RNA&quot;) celseq2 &lt;- NormalizeData(celseq2, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) celseq2 &lt;- FindVariableFeatures(celseq2, selection.method = &quot;vst&quot;, nfeatures = 2000) celseq2 &lt;- ScaleData(celseq2) celseq2[[&quot;tech&quot;]] &lt;- &quot;celseq2&quot; # Fluidigm C1 # Omit subset function because cells are already high quality. fluidigmc1 &lt;- CreateSeuratObject(counts = fluidigmc1.data) VlnPlot(fluidigmc1, &quot;nFeature_RNA&quot;) fluidigmc1 &lt;- NormalizeData(fluidigmc1, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) fluidigmc1 &lt;- FindVariableFeatures(fluidigmc1, selection.method = &quot;vst&quot;, nfeatures = 2000) fluidigmc1 &lt;- ScaleData(fluidigmc1) fluidigmc1[[&quot;tech&quot;]] &lt;- &quot;fluidigmc1&quot; # SMART-Seq2 # In subset, use low.thresholds = 2500. smartseq2 &lt;- CreateSeuratObject(counts = smartseq2.data) VlnPlot(smartseq2, &quot;nFeature_RNA&quot;) smartseq2 &lt;- subset(smartseq2, subset = nFeature_RNA &gt; 2500) VlnPlot(smartseq2, &quot;nFeature_RNA&quot;) smartseq2 &lt;- NormalizeData(smartseq2, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) smartseq2 &lt;- FindVariableFeatures(smartseq2, selection.method = &quot;vst&quot;, nfeatures = 2000) smartseq2 &lt;- ScaleData(smartseq2) smartseq2[[&quot;tech&quot;]] &lt;- &quot;smartseq2&quot; # This code sub-samples the data in order to speed up calculations and not use too much memory. Idents(celseq) &lt;- &quot;tech&quot; celseq &lt;- subset(celseq, downsample = 500, seed = 1) Idents(celseq2) &lt;- &quot;tech&quot; celseq2 &lt;- subset(celseq2, downsample = 500, seed = 1) Idents(fluidigmc1) &lt;- &quot;tech&quot; fluidigmc1 &lt;- subset(fluidigmc1, downsample = 500, seed = 1) Idents(smartseq2) &lt;- &quot;tech&quot; smartseq2 &lt;- subset(smartseq2, downsample = 500, seed = 1) # Save the sub-sampled Seurat objects save(celseq, celseq2, fluidigmc1, smartseq2, file = Rda.sparse.path) "],
["cluster-pancreatic-datasets-without-batch-correction.html", "11 Cluster pancreatic datasets without batch correction", " 11 Cluster pancreatic datasets without batch correction Let us cluster all the pancreatic islet datasets together and see whether there is a batch effect. # load(Rda.sparse.path) # Merge Seurat objects. Original sample identities are stored in gcdata[[&quot;tech&quot;]]. # Cell names will now have the format tech_cellID (smartseq2_cell1...) add.cell.ids &lt;- c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;) gcdata &lt;- merge(x = celseq, y = list(celseq2, fluidigmc1, smartseq2), add.cell.ids = add.cell.ids, merge.data = FALSE) Idents(gcdata) &lt;- &quot;tech&quot; # use identity based on sample identity # Look at how the number of genes per cell varies across the different technologies. VlnPlot(gcdata, &quot;nFeature_RNA&quot;, group.by = &quot;tech&quot;) # The merged data must be normalized and scaled (but you only need to scale the variable genes). # Let us also find the variable genes again this time using all the pancreas data. gcdata &lt;- NormalizeData(gcdata, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000) var.genes &lt;- SelectIntegrationFeatures(SplitObject(gcdata, split.by = &quot;tech&quot;), nfeatures = 2000, verbose = TRUE, fvf.nfeatures = 2000, selection.method = &quot;vst&quot;) VariableFeatures(gcdata) &lt;- var.genes gcdata &lt;- ScaleData(gcdata, features = VariableFeatures(gcdata)) # Do PCA on data including only the variable genes. gcdata &lt;- RunPCA(gcdata, features = VariableFeatures(gcdata), npcs = 40, ndims.print = 1:5, nfeatures.print = 5) # Color the PC biplot by the scRNA-seq technology. Hint: use DimPlot # Which technologies look similar to one another? DimPlot(gcdata, reduction = &quot;pca&quot;, dims = c(1, 2), group.by = &quot;tech&quot;) # Cluster the cells using the first twenty principal components. gcdata &lt;- FindNeighbors(gcdata, reduction = &quot;pca&quot;, dims = 1:20, k.param = 20) gcdata &lt;- FindClusters(gcdata, resolution = 0.8, algorithm = 4, random.seed = 100) # Create a UMAP visualization. gcdata &lt;- RunUMAP(gcdata, dims = 1:20, reduction = &quot;pca&quot;, n.neighbors = 15, min.dist = 0.5, spread = 1, metric = &quot;euclidean&quot;, seed.use = 1) # Visualize the Leiden clustering and the batches on the UMAP. # Remember, the clustering is stored in @meta.data in column seurat_clusters and the technology is # stored in the column tech. Remember you can also use DimPlot DimPlot(gcdata, reduction = &quot;umap&quot;, group.by = &quot;seurat_clusters&quot;) DimPlot(gcdata, reduction = &quot;umap&quot;, group.by = &quot;tech&quot;) # Are you surprised by the results? Compare to your expectations from the PC biplot of PC1 vs PC2. # What explains these results? # Adjusted rand index test for overlap between technology and cluster labelings. # This goes between 0 (completely dissimilar clustering) to 1 (identical clustering). # The adjustment corrects for chance grouping between cluster elements. # https://davetang.org/muse/2017/09/21/adjusted-rand-index/ ari &lt;- dplyr::select(gcdata[[]], tech, seurat_clusters) ari$tech &lt;- plyr::mapvalues(ari$tech, from = c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;), to = c(0, 1, 2, 3)) adj.rand.index(as.numeric(ari$tech), as.numeric(ari$seurat_clusters)) # Save current progress. save(gcdata, file = Rda.path) # To load the data, run the following command. # load(Rda.path) 11.0.1 Batch correction: canonical correlation analysis (CCA)+ mutual nearest neighbors (MNN) using Seurat v3 Here we use Seurat v3 to see to what extent it can remove potential batch effects. # load(Rda.sparse.path) # The first piece of code will identify variable genes that are highly variable in at least 2/4 datasets. We will use these variable genes in our batch correction. # Why would we implement such a requirement? ob.list &lt;- list(celseq, celseq2, fluidigmc1, smartseq2) # Identify anchors on the 4 pancreatic islet datasets, commonly shared variable genes across samples, # and integrate samples. gcdata.anchors &lt;- FindIntegrationAnchors(object.list = ob.list, anchor.features = 2000, dims = 1:30) gcdata &lt;- IntegrateData(anchorset = gcdata.anchors, dims = 1:30) DefaultAssay(gcdata) &lt;- &quot;integrated&quot; # Run the standard workflow for visualization and clustering. # The integrated data object only stores the commonly shared variable genes. gcdata &lt;- ScaleData(gcdata, do.center = T, do.scale = F) gcdata &lt;- RunPCA(gcdata, npcs = 40, ndims.print = 1:5, nfeatures.print = 5) DimPlot(gcdata, dims = c(1, 2), reduction = &quot;pca&quot;, split.by = &quot;tech&quot;) # Clustering. Choose the dimensional reduction type to use and the number of aligned # canonical correlation vectors to use. gcdata &lt;- FindNeighbors(gcdata, reduction = &quot;pca&quot;, dims = 1:20, k.param = 20) gcdata &lt;- FindClusters(gcdata, resolution = 0.8, algorithm = 4, random.seed = 100) # UMAP. Choose the dimensional reduction type to use and the number of aligned # canonical correlation vectors to use. gcdata &lt;- RunUMAP(gcdata, dims = 1:30, reduction = &quot;pca&quot;, n.neighbors = 15, min.dist = 0.5, spread = 1, metric = &quot;euclidean&quot;, seed.use = 1) # After data integration, use the original expression data in all visualization and DE tests. # The integrated data must not be used in DE tests as it violates assumptions of independence in DE tests! DefaultAssay(gcdata) &lt;- &quot;RNA&quot; # Visualize the Louvain clustering and the batches on the UMAP. # Remember, the clustering is stored in @meta.data in column seurat_clusters # and the technology is stored in the column tech. Remember you can also use DimPlot. p1 &lt;- DimPlot(gcdata, reduction = &quot;umap&quot;, group.by = &quot;seurat_clusters&quot;) p2 &lt;- DimPlot(gcdata, reduction = &quot;umap&quot;, group.by = &quot;tech&quot;) p1 + p2 # Let&#39;s look to see how the adjusted rand index changed compared to using no batch correction. ari &lt;- dplyr::select(gcdata[[]], tech, seurat_clusters) ari$tech &lt;- plyr::mapvalues(ari$tech, from = c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;), to = c(0, 1, 2, 3)) adj.rand.index(as.numeric(ari$tech), as.numeric(ari$seurat_clusters)) # We can also identify conserved marker genes across the batches. Differential gene expression is # done across each batch, and the p-values are combined. markers &lt;- FindConservedMarkers(gcdata, ident.1 = 0, grouping.var = &quot;tech&quot;, assay = &quot;RNA&quot;, print.bar = T) head(markers) # Visualize the expression of the first 5 marker genes on UMAP across the different batches using DoHeatmap. gcdata &lt;- ScaleData(gcdata, features = rownames(gcdata), do.center = T, do.scale = F) DoHeatmap(gcdata, features = rownames(markers)[1:5], group.by = &quot;tech&quot;, disp.max = 3) # Markers for pancreatic cells from &quot;A Single-Cell Transcriptome Atlas of the # Human Pancreas&quot;.https://www.cell.com/cell-systems/pdfExtended/S2405-4712(16)30292-7 genes &lt;- c(&quot;GCG&quot;, &quot;INS&quot;, &quot;SST&quot;, &quot;PPY&quot;, &quot;PRSS1&quot;, &quot;KRT19&quot;, &quot;PECAM1&quot;, &quot;COL1A1&quot;) FeaturePlot(gcdata, genes, ncol = 4) # Save current progress. save(gcdata, file = Rda.Seurat3.path) # To load the data, run the following command. # load(Rda.Seurat3.path) 11.0.2 Batch correction: integrative non-negative matrix factorization (NMF) using LIGER Here we use integrative non-negative matrix factorization to see to what extent it can remove potential batch effects. The important parameters in the batch correction are the number of factors (k), the penalty parameter (lambda), and the clustering resolution. The number of factors sets the number of factors (consisting of shared and dataset-specific factors) used in factorizing the matrix. The penalty parameter sets the balance between factors shared across the batches and factors specific to the individual batches. The default setting of lambda=5.0 is usually used by the Macosko lab. Resolution=1.0 is used in the Louvain clustering of the shared neighbor factors that have been quantile normalized. # load(Rda.sparse.path) ob.list &lt;- list(&quot;celseq&quot; = celseq, &quot;celseq2&quot; = celseq2, &quot;fluidigmc1&quot; = fluidigmc1, &quot;smartseq2&quot; = smartseq2) # Identify variable genes that are variable across most samples. var.genes &lt;- SelectIntegrationFeatures(ob.list, nfeatures = 2000, verbose = TRUE, fvf.nfeatures = 2000, selection.method = &quot;vst&quot;) # Next we create a LIGER object with raw counts data from each batch. data.liger &lt;- createLiger(sapply(ob.list, function(data) data[[&#39;RNA&#39;]]@counts[, colnames(data)]), remove.missing = F) # Normalize gene expression for each batch. data.liger &lt;- liger::normalize(data.liger) # Use my method or Liger method for selecting variable genes (var.thresh changes number of variable genes). data.liger@var.genes &lt;- var.genes # data.liger &lt;- selectGenes(data.liger, var.thresh = 0.1, do.plot = F) # Print out the number of variable genes for LIGER analysis. print(length(data.liger@var.genes)) # Scale the gene expression across the datasets. # Why does LIGER not center the data? Hint, think about the use of # non-negative matrix factorization and the constraints that this imposes. data.liger &lt;- scaleNotCenter(data.liger) # These two steps take 10-20 min. Only run them if you finish with the rest of the code. # Use the `suggestK` function to determine the appropriate number of factors to use. # Use the `suggestLambda` function to find the smallest lambda for which the alignment metric stabilizes. # k.suggest &lt;- suggestK(data.liger, k.test = seq(5, 30, 5), plot.log2 = T) # lambda.suggest &lt;- suggestLambda(gcdata.liger, k.suggest) # Use alternating least squares (ALS) to factorize the matrix. # Next, quantile align the factor loadings across the datasets, and do clustering. k.suggest &lt;- 20 # with this line, we do not use the suggested k by suggestK() lambda.suggest &lt;- 5 # with this line, we do not use the suggested lambda by suggestLambda() set.seed(100) # optimizeALS below is stochastic data.liger &lt;- optimizeALS(data.liger, k = k.suggest, lamda = lambda.suggest) # What do matrices H, V, and W represent, and what are their dimensions? dim(data.liger@H$celseq) dim(data.liger@V$celseq) dim(data.liger@W) # Next, do clustering of cells in shared nearest factor space. # Build SNF graph, do quantile normalization, cluster quantile normalized data data.liger &lt;- quantileAlignSNF(data.liger, resolution = 1) # SNF clustering and quantile alignment # What are the dimensions of H.norm. What does this represent? dim(data.liger@H.norm) # Let&#39;s see what the liger data looks like mapped onto a UMAP visualization. data.liger &lt;- runUMAP(data.liger, n_neighbors = 15, min_dist = 0.5) # conda install -c conda-forge umap-learn p &lt;- plotByDatasetAndCluster(data.liger, return.plots = T) print(p[[1]]) # plot by dataset plot_grid(p[[1]], p[[2]]) # Let&#39;s look to see how the adjusted rand index changed compared to using no batch correction. tech &lt;- unlist(lapply(1:length(data.liger@H), function(x) { rep(names(data.liger@H)[x], nrow(data.liger@H[[x]]))})) clusters &lt;- data.liger@alignment.clusters ari &lt;- data.frame(&quot;tech&quot; = tech, &quot;clusters&quot; = clusters) ari$tech &lt;- plyr::mapvalues(ari$tech, from = c(&quot;celseq&quot;, &quot;celseq2&quot;, &quot;fluidigmc1&quot;, &quot;smartseq2&quot;), to = c(0, 1, 2, 3)) adj.rand.index(as.numeric(ari$tech), as.numeric(ari$clusters)) # Look at proportion of each batch in each cluster, and look at factor loadings across clusters plotClusterProportions(data.liger) plotClusterFactors(data.liger, use.aligned = T) # Look at genes that are specific to a dataset and shared across datasets. # Use the plotWordClouds function and choose 2 datasets. pdf(paste0(mydir, &quot;word_clouds.pdf&quot;)) plotWordClouds(data.liger, dataset1 = &quot;celseq2&quot;, dataset2 = &quot;smartseq2&quot;) dev.off() # Look at factor loadings for each cell using plotFactors. pdf(paste0(mydir, &quot;plot_factors.pdf&quot;)) plotFactors(data.liger) dev.off() # Identify shared and batch-specific marker genes from liger factorization. # Use the getFactorMarkers function and choose 2 datasets. # Then plot some genes of interest using plotGene. markers &lt;- getFactorMarkers(data.liger, dataset1 = &quot;celseq2&quot;, dataset2 = &quot;smartseq2&quot;, num.genes = 10) plotGene(data.liger, gene = &quot;INS&quot;) # Save current progress. save(data.liger, file = Rda.liger.path) # To load the data, run the following command. # load(Rda.liger.path) "],
["additional-exploration-regressing-out-unwanted-covariates.html", "12 Additional exploration: Regressing out unwanted covariates", " 12 Additional exploration: Regressing out unwanted covariates Learn how to regress out different technical covariates (number of UMIs, number of genes, percent mitochondrial reads) by studying Seurat’s PBMC tutorial and the ScaleData() function. "],
["additional-exploration-kbet.html", "13 Additional exploration: kBET", " 13 Additional exploration: kBET Within your RStudio session, install k-nearest neighbour batch effect test and learn how to use its functionality to quantify batch effects in the pancreatic data. "],
["additional-exploration-seurat-3.html", "14 Additional exploration: Seurat 3", " 14 Additional exploration: Seurat 3 Read how new version of Seurat does data integration "],
["acknowledgements.html", "15 Acknowledgements", " 15 Acknowledgements This document builds off a tutorial from the Seurat website and a tutorial from the LIGER website. "],
["advanced-topics-pseudotime-cell-trajectories.html", "16 Advanced Topics: Pseudotime Cell Trajectories 16.1 Google Slides", " 16 Advanced Topics: Pseudotime Cell Trajectories 16.1 Google Slides library(Seurat) pbmc_small@assays$RNA@counts[,1:10, 1:3] ## 230 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## [[ suppressing 10 column names &#39;ATGCCAGAACGACT&#39;, &#39;CATGGCCTGTGCAT&#39;, &#39;GAACCTGATGAACC&#39; ... ]] ## [[ suppressing 10 column names &#39;ATGCCAGAACGACT&#39;, &#39;CATGGCCTGTGCAT&#39;, &#39;GAACCTGATGAACC&#39; ... ]] ## ## MS4A1 . . . . . . . . . . ## CD79B 1 . . . . . . . . 1 ## CD79A . . . . . . . . . . ## HLA-DRA . 1 . . 1 1 . 1 . . ## TCL1A . . . . . . . . . . ## HLA-DQB1 1 . . . . . . . . . ## HVCN1 . . . . . . . . . . ## HLA-DMB . . . . . . . . . . ## LTB 3 7 11 13 3 4 6 4 2 21 ## LINC00926 . . . . . . . . . . ## FCER2 . . . . . . . . . . ## SP100 1 . 1 1 . . . . . 1 ## NCF1 . . . . . . . . . . ## PPP3CC . . . . . 1 . . . . ## EAF2 . . . . . . . . . . ## PPAPDC1B . . . . . . . . . . ## CD19 . . . . . . . . . . ## KIAA0125 . . . . . . . . . . ## CYB561A3 . . . . . . . . . . ## CD180 . . . . . . . . . . ## RP11-693J15.5 . . . . . . . . . . ## FAM96A . 1 . . . . . . . . ## CXCR4 1 1 . 6 . 2 4 1 . 4 ## STX10 . . 1 . . 1 . 1 . . ## SNHG7 . 2 . . . . . . . 1 ## NT5C . . . . . . . . . . ## BANK1 . 1 . . . . . . . . ## IGLL5 . . . . . . . . . . ## CD200 . . . . . . . . . . ## FCRLA . . . . . . . . . . ## CD3D 4 4 4 5 4 4 3 2 2 2 ## NOSIP . 3 2 2 3 1 1 3 2 1 ## SAFB2 . 1 . 1 . 1 1 . . 1 ## CD2 1 . 2 2 . 1 . 1 2 1 ## IL7R 5 2 1 2 2 . 1 12 . 9 ## PIK3IP1 . . 1 . . 2 3 2 3 . ## MPHOSPH6 1 1 . . . . 1 1 1 1 ## KHDRBS1 . 1 1 1 36 . . . . . ## MAL 1 1 . 1 . . . 1 . 1 ## CCR7 . 5 . . 2 . 1 1 . 1 ## THYN1 . 2 1 1 . 2 1 . 1 . ## TAF7 . 2 . 2 1 2 . 2 3 1 ## LDHB 3 2 1 6 5 3 4 . 1 6 ## TMEM123 3 3 . 4 2 1 1 2 1 1 ## CCDC104 . . . 2 . 1 . 1 . . ## EPC1 1 . 1 . . 1 . 1 1 1 ## EIF4A2 3 1 2 5 2 4 3 2 3 . ## CD3E . 2 1 4 3 1 3 4 2 . ## TMUB1 1 . . . . 1 1 1 . . ## BLOC1S4 1 . 2 . 2 . . . 1 . ## ## .............................. ## ........suppressing 130 rows in show(); maybe adjust &#39;options(max.print= *, width = *)&#39; ## .............................. ## [[ suppressing 10 column names &#39;ATGCCAGAACGACT&#39;, &#39;CATGGCCTGTGCAT&#39;, &#39;GAACCTGATGAACC&#39; ... ]] ## ## GNG11 . . . . . . . . . . ## CLU . . . . . . . . . . ## HIST1H2AC . . . . . . . . . . ## NCOA4 . 1 . . . . . . 1 . ## GP9 . . . . . . . . . . ## FERMT3 . 1 . . . . . . . . ## ODC1 1 . . . . 1 . . . . ## CD9 . . . . . . . . . . ## RUFY1 . . . . . . . . . . ## TUBB1 . 1 . . . . . . . . ## TALDO1 1 2 . . 2 . . . . . ## TREML1 . . . . . . . . . . ## NGFRAP1 . . . . . 1 . . . . ## PGRMC1 . . . . . . . . . . ## CA2 . . . . . . . . . . ## ITGA2B . . . . . . . . . . ## MYL9 . . . . . . . . . . ## TMEM40 . . . . . . . . . . ## PARVB . . . . . . . . . . ## PTCRA . . . . . . . . . . ## ACRBP 1 . . . . . . . . . ## TSC22D1 . . . . . . . . . . ## VDAC3 . . . 1 . . 1 . . 1 ## GZMB . . . . . . . . . . ## GZMA . . . . . . 1 . . . ## GNLY . . . 1 . . . . . . ## FGFBP2 . . . . . . . . . . ## AKR1C3 . . . . . . . . . . ## CCL4 . . . . . . . . . . ## PRF1 . 1 . . . . . . . . ## GZMH . . . . . . . . . . ## XBP1 1 . 1 1 2 . . 1 . . ## GZMM . 1 . . 1 1 . . . . ## PTGDR . . . . . . . . . . ## IGFBP7 . . . . . . . . . . ## TTC38 . . . . . . . . . . ## KLRD1 . . . . . . . . . . ## ARHGDIA . 1 . . . . . . . . ## IL2RB . . . . . . . . . . ## CLIC3 . . . . . . . . . . ## PPP1R18 . 1 . . . 1 . . . 1 ## CD247 . 1 1 . 2 1 . . . . ## ALOX5AP 1 . . . 1 . . 1 . . ## XCL2 . . . . . . . . . . ## C12orf75 . . . . . . . . . . ## RARRES3 1 . . 3 . 1 1 . 1 . ## PCMT1 . . . . . . . . . . ## LAMP1 1 . . . . . 1 . . . ## SPON2 . 1 . . . . . . . . ## S100B . . . . . . . . . . pbmc_small@assays$RNA@counts[,1:10, 1:3] Some text to see if the output from above overlaps with the text below it. "],
["single-cell-resources.html", "17 Single Cell Resources 17.1 Comprehensive list of single-cell resources 17.2 Computational packages for single-cell analysis 17.3 eLife Commentary on the Human Cell Atlas 17.4 Online courses", " 17 Single Cell Resources 17.1 Comprehensive list of single-cell resources https://github.com/seandavi/awesome-single-cell 17.2 Computational packages for single-cell analysis http://bioconductor.org/packages/devel/workflows/html/simpleSingleCell.html https://satijalab.org/seurat/ https://scanpy.readthedocs.io/ 17.3 eLife Commentary on the Human Cell Atlas link - Nature Commentary on the Human Cell Atlas - https://www.nature.com/news/the-human-cell-atlas-from-vision-to-reality-1.22854 17.4 Online courses Analysis of single cell RNA-seq data Single Cell Genomics Day Simple Single Cell Single Cell Transcriptomics R for Data Sciences "],
["references.html", "References", " References "]
]
